{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prove xgboost can overfit this problem\n",
    "\n",
    "## prove simple nn can overfit this problem\n",
    "\n",
    "### The conclusion of this experiment is that the embeddings from the pretrained model significantly distinguish differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = (\n",
    "    \"/Users/user/Documents/Coding/cro_location_intelligence/notebook/data/full_image\"\n",
    ")\n",
    "image_name_list = os.listdir(image_folder_path)\n",
    "image_name_list.sort()\n",
    "image_name_list = [\n",
    "    image_name for image_name in image_name_list if not image_name.startswith(\".\")\n",
    "]\n",
    "image_path_list = [\n",
    "    os.path.join(image_folder_path, image_name) for image_name in image_name_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066\n",
      "['1025', '8396', '8572', '1058', '1095']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = (\n",
    "    \"/Users/user/Documents/Coding/cro_location_intelligence/notebook/7 BE for Ford.xlsx\"\n",
    ")\n",
    "df_dict = pd.read_excel(data_path, sheet_name=None)\n",
    "store_id_list = df_dict[\"Train\"][\"store_id\"].tolist()\n",
    "store_id_list += df_dict[\"Test2022\"][\"store_id\"].tolist()\n",
    "store_id_list = [str(i) for i in store_id_list]\n",
    "print(len(store_id_list))\n",
    "print(store_id_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9997\n",
      "['10', '100', '1000', '10000', '10001']\n"
     ]
    }
   ],
   "source": [
    "store_id_we_have = []\n",
    "for image_name in image_name_list:\n",
    "    store_id_we_have.append(image_name.split(\".\")[0])\n",
    "print(len(store_id_we_have))\n",
    "print(store_id_we_have[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4926\n",
      "5350\n",
      "5651\n",
      "6034\n",
      "6298\n",
      "9143\n",
      "9295\n",
      "9364\n",
      "9381\n",
      "9385\n",
      "9454\n",
      "11022\n",
      "11185\n",
      "11397\n",
      "11413\n",
      "12007\n",
      "13099\n",
      "13218\n",
      "13947\n",
      "14422\n",
      "17542\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "store_id_we_dont_have = []\n",
    "for id in store_id_list:\n",
    "    if id not in store_id_we_have:\n",
    "        print(id)\n",
    "        store_id_we_dont_have.append(id)\n",
    "\n",
    "print(len(store_id_we_dont_have))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1066"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(store_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\"store_id,sum_pop_in_voronoi,voronoi_area,voronoi_density,cro_open_year,CRO_store_length,CRO_store_parking,CRO_store_stock_area,CRO_store_total_area,CRO_store_width,CRO_store_shophouse_blocks,store_sales_area,latitude,longitude,prdct_AC,prdct_DC,prdct_FM,prdct_FP,prdct_GP,prdct_KS,prdct_SP,prdct_VF,prdct_XT,population,POIs_entry_point_50m,POIs_entry_point_200m,POIs_entry_point_300m,POIs_entry_point_500m,POIs_entry_point_1000m,POIs_entry_point_2000m,POIs_industrial_area_50m,POIs_industrial_area_200m,POIs_industrial_area_300m,POIs_industrial_area_500m,POIs_industrial_area_1000m,POIs_industrial_area_2000m,POIs_low_rise_residential_area_50m,POIs_low_rise_residential_area_200m,POIs_low_rise_residential_area_300m,POIs_low_rise_residential_area_500m,POIs_low_rise_residential_area_1000m,POIs_low_rise_residential_area_2000m,POIs_market_area_50m,POIs_market_area_200m,POIs_market_area_300m,POIs_market_area_500m,POIs_market_area_1000m,POIs_market_area_2000m,POIs_tourism_area_50m,POIs_tourism_area_200m,POIs_tourism_area_300m,POIs_tourism_area_500m,POIs_tourism_area_1000m,POIs_tourism_area_2000m,POIs_high_rise_residential_50m,POIs_high_rise_residential_200m,POIs_high_rise_residential_300m,POIs_high_rise_residential_500m,POIs_high_rise_residential_1000m,POIs_high_rise_residential_2000m,POIs_government_area_50m,POIs_government_area_200m,POIs_government_area_300m,POIs_government_area_500m,POIs_government_area_1000m,POIs_government_area_2000m,POIs_entertainment_area_50m,POIs_entertainment_area_200m,POIs_entertainment_area_300m,POIs_entertainment_area_500m,POIs_entertainment_area_1000m,POIs_entertainment_area_2000m,POIs_gas_stations_50m,POIs_gas_stations_200m,POIs_gas_stations_300m,POIs_gas_stations_500m,POIs_gas_stations_1000m,POIs_gas_stations_2000m,POIs_public_transportation_50m,POIs_public_transportation_200m,POIs_public_transportation_300m,POIs_public_transportation_500m,POIs_public_transportation_1000m,POIs_public_transportation_2000m,POIs_healthcare_centers_50m,POIs_healthcare_centers_200m,POIs_healthcare_centers_300m,POIs_healthcare_centers_500m,POIs_healthcare_centers_1000m,POIs_healthcare_centers_2000m,POIs_office_building_50m,POIs_office_building_200m,POIs_office_building_300m,POIs_office_building_500m,POIs_office_building_1000m,POIs_office_building_2000m,POIs_housing_residential_area_50m,POIs_housing_residential_area_200m,POIs_housing_residential_area_300m,POIs_housing_residential_area_500m,POIs_housing_residential_area_1000m,POIs_housing_residential_area_2000m,POIs_transportation_center_50m,POIs_transportation_center_200m,POIs_transportation_center_300m,POIs_transportation_center_500m,POIs_transportation_center_1000m,POIs_transportation_center_2000m,POIs_education_area_50m,POIs_education_area_200m,POIs_education_area_300m,POIs_education_area_500m,POIs_education_area_1000m,POIs_education_area_2000m,POIs_competitors_50m,POIs_competitors_200m,POIs_competitors_300m,POIs_competitors_500m,POIs_competitors_1000m,POIs_competitors_2000m,main_profile_NDF,main_profile_คมนาคมสาธารณะ,main_profile_ที่พักอาศัย/ตลาด,main_profile_ปั๊มน้ำมัน,main_profile_สถานที่ท่องเที่ยว,main_profile_สถานบันเทิง,main_profile_สถานศึกษา,main_profile_สำนักงาน,main_profile_โรงงาน,main_profile_โรงพยาบาล,sub_profile_NDF,sub_profile_คมนาคมสาธารณะ,sub_profile_ที่พักอาศัย/ตลาด,sub_profile_ปั๊มน้ำมัน,sub_profile_สถานบันเทิง,sub_profile_สถานศึกษา,sub_profile_สำนักงาน,sub_profile_โรงงาน,sub_profile_โรงพยาบาล,strategic_location_4 เหล่าทัพ,strategic_location_Community/MiniMall/ห้างสรรพสินค้า,strategic_location_NDF,strategic_location_Office Building,strategic_location_การเคหะ,strategic_location_คอนโด (เซ็นสัญญากลุ่ม),strategic_location_คอนโด (เซ็นสัญญาเดี่ยว),strategic_location_ทำเลพิเศษอื่นๆ,strategic_location_ที่อยู่อาศัย เฉพาะเซ็นสัญญากลุ่ม (BSP),strategic_location_มหาวิทยาลัย/ราชภัฏ/วิทยาลัย/เทคนิค,strategic_location_สนามบิน,strategic_location_แนวรถไฟฟ้า,strategic_location_โรงงาน/นิคมอุตสาหกรรม,strategic_location_โรงพยาบาลชั้นหนึ่ง รัฐบาล/เอกชน,strategic_location_โรงเรียนประถม-มัธยมประจำจังหวัด,strategic_location_ไม่ใช่ Strategic Location,CRO_store_type_BU,CRO_store_type_Booth,CRO_store_type_SA,CRO_store_type_SH,CRO_store_franchise_Co,CRO_store_franchise_PTTOR,CRO_store_franchise_SBP,open_month,y_nor,green_wkday_12_cr_0,green_wkday_12_cr_1,green_wkday_12_cr_2,green_wkday_12_cr_3,green_wkday_12_cr_4,green_wkday_12_cr_5,green_wkday_12_cr_6,green_wkday_12_cr_7,orange_wkday_12_cr_0,orange_wkday_12_cr_1,orange_wkday_12_cr_2,orange_wkday_12_cr_3,orange_wkday_12_cr_4,orange_wkday_12_cr_5,orange_wkday_12_cr_6,orange_wkday_12_cr_7,red_wkday_12_cr_0,red_wkday_12_cr_1,red_wkday_12_cr_2,red_wkday_12_cr_3,red_wkday_12_cr_4,red_wkday_12_cr_5,red_wkday_12_cr_6,red_wkday_12_cr_7,maroon_wkday_12_cr_0,maroon_wkday_12_cr_1,maroon_wkday_12_cr_2,maroon_wkday_12_cr_3,maroon_wkday_12_cr_4,maroon_wkday_12_cr_5,maroon_wkday_12_cr_6,maroon_wkday_12_cr_7,green_wkday_18_cr_0,green_wkday_18_cr_1,green_wkday_18_cr_2,green_wkday_18_cr_3,green_wkday_18_cr_4,green_wkday_18_cr_5,green_wkday_18_cr_6,green_wkday_18_cr_7,orange_wkday_18_cr_0,orange_wkday_18_cr_1,orange_wkday_18_cr_2,orange_wkday_18_cr_3,orange_wkday_18_cr_4,orange_wkday_18_cr_5,orange_wkday_18_cr_6,orange_wkday_18_cr_7,red_wkday_18_cr_0,red_wkday_18_cr_1,red_wkday_18_cr_2,red_wkday_18_cr_3,red_wkday_18_cr_4,red_wkday_18_cr_5,red_wkday_18_cr_6,red_wkday_18_cr_7,maroon_wkday_18_cr_0,maroon_wkday_18_cr_1,maroon_wkday_18_cr_2,maroon_wkday_18_cr_3,maroon_wkday_18_cr_4,maroon_wkday_18_cr_5,maroon_wkday_18_cr_6,maroon_wkday_18_cr_7,green_wkend_12_cr_0,green_wkend_12_cr_1,green_wkend_12_cr_2,green_wkend_12_cr_3,green_wkend_12_cr_4,green_wkend_12_cr_5,green_wkend_12_cr_6,green_wkend_12_cr_7,orange_wkend_12_cr_0,orange_wkend_12_cr_1,orange_wkend_12_cr_2,orange_wkend_12_cr_3,orange_wkend_12_cr_4,orange_wkend_12_cr_5,orange_wkend_12_cr_6,orange_wkend_12_cr_7,red_wkend_12_cr_0,red_wkend_12_cr_1,red_wkend_12_cr_2,red_wkend_12_cr_3,red_wkend_12_cr_4,red_wkend_12_cr_5,red_wkend_12_cr_6,red_wkend_12_cr_7,maroon_wkend_12_cr_0,maroon_wkend_12_cr_1,maroon_wkend_12_cr_2,maroon_wkend_12_cr_3,maroon_wkend_12_cr_4,maroon_wkend_12_cr_5,maroon_wkend_12_cr_6,maroon_wkend_12_cr_7,green_wkend_18_cr_0,green_wkend_18_cr_1,green_wkend_18_cr_2,green_wkend_18_cr_3,green_wkend_18_cr_4,green_wkend_18_cr_5,green_wkend_18_cr_6,green_wkend_18_cr_7,orange_wkend_18_cr_0,orange_wkend_18_cr_1,orange_wkend_18_cr_2,orange_wkend_18_cr_3,orange_wkend_18_cr_4,orange_wkend_18_cr_5,orange_wkend_18_cr_6,orange_wkend_18_cr_7,red_wkend_18_cr_0,red_wkend_18_cr_1,red_wkend_18_cr_2,red_wkend_18_cr_3,red_wkend_18_cr_4,red_wkend_18_cr_5,red_wkend_18_cr_6,red_wkend_18_cr_7,maroon_wkend_18_cr_0,maroon_wkend_18_cr_1,maroon_wkend_18_cr_2,maroon_wkend_18_cr_3,maroon_wkend_18_cr_4,maroon_wkend_18_cr_5,maroon_wkend_18_cr_6,maroon_wkend_18_cr_7,road_length_path_cr_0,road_length_path_cr_1,road_length_path_cr_2,road_length_path_cr_3,road_length_path_cr_4,road_length_path_cr_5,road_length_path_cr_6,road_length_path_cr_7,road_length_bus_stop_cr_0,road_length_bus_stop_cr_1,road_length_bus_stop_cr_2,road_length_bus_stop_cr_3,road_length_bus_stop_cr_4,road_length_bus_stop_cr_5,road_length_bus_stop_cr_6,road_length_bus_stop_cr_7,road_length_track_cr_0,road_length_track_cr_1,road_length_track_cr_2,road_length_track_cr_3,road_length_track_cr_4,road_length_track_cr_5,road_length_track_cr_6,road_length_track_cr_7,road_length_trunk_cr_0,road_length_trunk_cr_1,road_length_trunk_cr_2,road_length_trunk_cr_3,road_length_trunk_cr_4,road_length_trunk_cr_5,road_length_trunk_cr_6,road_length_trunk_cr_7,road_length_primary_cr_0,road_length_primary_cr_1,road_length_primary_cr_2,road_length_primary_cr_3,road_length_primary_cr_4,road_length_primary_cr_5,road_length_primary_cr_6,road_length_primary_cr_7,road_length_footway_cr_0,road_length_footway_cr_1,road_length_footway_cr_2,road_length_footway_cr_3,road_length_footway_cr_4,road_length_footway_cr_5,road_length_footway_cr_6,road_length_footway_cr_7,road_length_secondary_cr_0,road_length_secondary_cr_1,road_length_secondary_cr_2,road_length_secondary_cr_3,road_length_secondary_cr_4,road_length_secondary_cr_5,road_length_secondary_cr_6,road_length_secondary_cr_7,road_length_tertiary_cr_0,road_length_tertiary_cr_1,road_length_tertiary_cr_2,road_length_tertiary_cr_3,road_length_tertiary_cr_4,road_length_tertiary_cr_5,road_length_tertiary_cr_6,road_length_tertiary_cr_7,road_length_unclassified_cr_0,road_length_unclassified_cr_1,road_length_unclassified_cr_2,road_length_unclassified_cr_3,road_length_unclassified_cr_4,road_length_unclassified_cr_5,road_length_unclassified_cr_6,road_length_unclassified_cr_7,road_length_service_cr_0,road_length_service_cr_1,road_length_service_cr_2,road_length_service_cr_3,road_length_service_cr_4,road_length_service_cr_5,road_length_service_cr_6,road_length_service_cr_7,road_length_residential_cr_0,road_length_residential_cr_1,road_length_residential_cr_2,road_length_residential_cr_3,road_length_residential_cr_4,road_length_residential_cr_5,road_length_residential_cr_6,road_length_residential_cr_7,prov_namt_กรุงเทพมหานคร,prov_namt_ปทุมธานี,store_franchise_Co,store_franchise_SBP,subset\"\"\"\n",
    "a = a.split(\",\")\n",
    "print(len(a))\n",
    "print(\"y_nor\" in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed model net\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# new_df_path = \"/Users/user/Documents/Coding/cro_location_intelligence/notebook/7 lat long with embedding.csv\"\n",
    "new_df_path = \"/Users/user/Documents/Coding/cro_location_intelligence/src/data/all_data_embedding.csv\"\n",
    "if not os.path.exists(new_df_path):\n",
    "    old_df_path = \"/Users/user/Documents/Coding/cro_location_intelligence/src/data/all_data_embedding_old.csv\"\n",
    "    # merge old embedding with new data\n",
    "    data_path = (\n",
    "        \"/Users/user/Documents/Coding/cro_location_intelligence/src/data/all_data.csv\"\n",
    "    )\n",
    "    old_df = pd.read_csv(old_df_path)\n",
    "    df = pd.read_csv(data_path)\n",
    "    # merge old_df to df with store_id\n",
    "    df = pd.merge(\n",
    "        df, old_df.filter(regex=\"^embedding_.*|store_id$\"), on=\"store_id\", how=\"left\"\n",
    "    )\n",
    "    # save\n",
    "    df.to_csv(new_df_path, index=False)\n",
    "\n",
    "    # output_dict = {}\n",
    "    # model = timm.create_model(\n",
    "    #     \"maxvit_tiny_tf_512.in1k\",\n",
    "    #     pretrained=True,\n",
    "    #     num_classes=0,  # remove classifier nn.Linear\n",
    "    # )\n",
    "    # model = model.eval()\n",
    "    # data_config = timm.data.resolve_model_data_config(model)\n",
    "    # transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    # # for image_name in image_name_list:\n",
    "    # batch_size = 4\n",
    "    # # check is file exist\n",
    "\n",
    "    # check_store_id_list = []\n",
    "    # for store_id in store_id_list:\n",
    "    #     image_name = store_id + \".png\"\n",
    "    #     image_path = os.path.join(image_folder_path, image_name)\n",
    "    #     if os.path.exists(image_path):\n",
    "    #         check_store_id_list.append(store_id)\n",
    "    # store_id_list = check_store_id_list\n",
    "    # print(\"len(store_id_list)\", len(store_id_list))\n",
    "    # # Iterate through store_ids in batches\n",
    "    # for batch_start in tqdm(\n",
    "    #     range(0, len(store_id_list), batch_size), desc=\"store_id batches\"\n",
    "    # ):\n",
    "    #     batch_store_ids = store_id_list[batch_start : batch_start + batch_size]\n",
    "    #     batch_images = []\n",
    "\n",
    "    #     # Load and preprocess images in the current batch\n",
    "    #     for store_id in batch_store_ids:\n",
    "    #         image_name = store_id + \".png\"\n",
    "    #         image_path = os.path.join(image_folder_path, image_name)\n",
    "    #         img = Image.open(image_path).convert(\"RGB\")\n",
    "    #         batch_images.append(transforms(img))\n",
    "\n",
    "    #     # Stack images to create a batch\n",
    "    #     batch_images = torch.stack(batch_images)\n",
    "\n",
    "    #     # Forward pass for the batch\n",
    "    #     with torch.no_grad():\n",
    "    #         output = model.forward_features(batch_images)\n",
    "    #         output = model.forward_head(output, pre_logits=True)\n",
    "\n",
    "    #     # Store results in output_dict\n",
    "    #     for i, store_id in enumerate(batch_store_ids):\n",
    "    #         output_dict[store_id] = output.detach().numpy()[i]\n",
    "    #     # output is a (1, num_features) shaped tensor\n",
    "\n",
    "    # output_df = pd.DataFrame.from_dict(output_dict, orient=\"index\")\n",
    "    # output_df.head()\n",
    "    # output_df.columns = [\"embedding_\" + str(col + 1) for col in output_df.columns]\n",
    "    # # convert output_df store_id to int\n",
    "    # output_df[\"store_id\"] = output_df.index\n",
    "    # output_df.store_id = output_df.store_id.astype(int)\n",
    "    # data_path = (\n",
    "    #     \"/Users/user/Documents/Coding/cro_location_intelligence/src/data/all_data.csv\"\n",
    "    # )\n",
    "    # df = pd.read_csv(data_path)\n",
    "    # # merge df with output_df with columns store_id\n",
    "    # df = pd.merge(df, output_df, on=\"store_id\", how=\"inner\")\n",
    "\n",
    "    # # df = pd.concat([df, output_df], axis=1)\n",
    "    # df.to_csv(new_df_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(new_df_path)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.566370614359172, 16, 0.7853981633974483)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "r = 2\n",
    "circle_area = np.pi * r**2\n",
    "square_area = (2 * r) ** 2\n",
    "circle_area, square_area, circle_area / square_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nan in df\n",
    "df.isnull().sum()\n",
    "# drop nan\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns by add prefix \"embedding_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 2 df by index\n",
    "import pandas as pd\n",
    "\n",
    "# # convert output_dict to dataframe\n",
    "# if os.path.exists(new_df_path) is False:\n",
    "#     output_df = pd.DataFrame.from_dict(output_dict, orient=\"index\")\n",
    "#     output_df.head()\n",
    "#     output_df.columns = [\"embedding_\" + str(col + 1) for col in output_df.columns]\n",
    "#     # convert output_df store_id to int\n",
    "#     output_df[\"store_id\"] = output_df.index\n",
    "#     output_df.store_id = output_df.store_id.astype(int)\n",
    "#     data_path = (\n",
    "#         \"/Users/user/Documents/Coding/cro_location_intelligence/src/data/all_data.csv\"\n",
    "#     )\n",
    "#     df = pd.read_csv(data_path)\n",
    "#     # merge df with output_df with columns store_id\n",
    "#     df = pd.merge(df, output_df, on=\"store_id\", how=\"inner\")\n",
    "\n",
    "#     # df = pd.concat([df, output_df], axis=1)\n",
    "#     df.to_csv(new_df_path, index=False)\n",
    "# else:\n",
    "#     df = pd.read_csv(new_df_path)\n",
    "#     df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['store_id', 'sum_pop_in_voronoi', 'voronoi_area', 'voronoi_density', 'cro_open_year', 'CRO_store_length', 'CRO_store_parking', 'CRO_store_stock_area', 'CRO_store_total_area', 'CRO_store_width', 'CRO_store_shophouse_blocks', 'store_sales_area', 'latitude', 'longitude', 'prdct_AC', 'prdct_DC', 'prdct_FM', 'prdct_FP', 'prdct_GP', 'prdct_KS', 'prdct_SP', 'prdct_VF', 'prdct_XT', 'population', 'POIs_entry_point_50m', 'POIs_entry_point_200m', 'POIs_entry_point_300m', 'POIs_entry_point_500m', 'POIs_entry_point_1000m', 'POIs_entry_point_2000m', 'POIs_industrial_area_50m', 'POIs_industrial_area_200m', 'POIs_industrial_area_300m', 'POIs_industrial_area_500m', 'POIs_industrial_area_1000m', 'POIs_industrial_area_2000m', 'POIs_low_rise_residential_area_50m', 'POIs_low_rise_residential_area_200m', 'POIs_low_rise_residential_area_300m', 'POIs_low_rise_residential_area_500m', 'POIs_low_rise_residential_area_1000m', 'POIs_low_rise_residential_area_2000m', 'POIs_market_area_50m', 'POIs_market_area_200m', 'POIs_market_area_300m', 'POIs_market_area_500m', 'POIs_market_area_1000m', 'POIs_market_area_2000m', 'POIs_tourism_area_50m', 'POIs_tourism_area_200m', 'POIs_tourism_area_300m', 'POIs_tourism_area_500m', 'POIs_tourism_area_1000m', 'POIs_tourism_area_2000m', 'POIs_high_rise_residential_50m', 'POIs_high_rise_residential_200m', 'POIs_high_rise_residential_300m', 'POIs_high_rise_residential_500m', 'POIs_high_rise_residential_1000m', 'POIs_high_rise_residential_2000m', 'POIs_government_area_50m', 'POIs_government_area_200m', 'POIs_government_area_300m', 'POIs_government_area_500m', 'POIs_government_area_1000m', 'POIs_government_area_2000m', 'POIs_entertainment_area_50m', 'POIs_entertainment_area_200m', 'POIs_entertainment_area_300m', 'POIs_entertainment_area_500m', 'POIs_entertainment_area_1000m', 'POIs_entertainment_area_2000m', 'POIs_gas_stations_50m', 'POIs_gas_stations_200m', 'POIs_gas_stations_300m', 'POIs_gas_stations_500m', 'POIs_gas_stations_1000m', 'POIs_gas_stations_2000m', 'POIs_public_transportation_50m', 'POIs_public_transportation_200m', 'POIs_public_transportation_300m', 'POIs_public_transportation_500m', 'POIs_public_transportation_1000m', 'POIs_public_transportation_2000m', 'POIs_healthcare_centers_50m', 'POIs_healthcare_centers_200m', 'POIs_healthcare_centers_300m', 'POIs_healthcare_centers_500m', 'POIs_healthcare_centers_1000m', 'POIs_healthcare_centers_2000m', 'POIs_office_building_50m', 'POIs_office_building_200m', 'POIs_office_building_300m', 'POIs_office_building_500m', 'POIs_office_building_1000m', 'POIs_office_building_2000m', 'POIs_housing_residential_area_50m', 'POIs_housing_residential_area_200m', 'POIs_housing_residential_area_300m', 'POIs_housing_residential_area_500m', 'POIs_housing_residential_area_1000m', 'POIs_housing_residential_area_2000m', 'POIs_transportation_center_50m', 'POIs_transportation_center_200m', 'POIs_transportation_center_300m', 'POIs_transportation_center_500m', 'POIs_transportation_center_1000m', 'POIs_transportation_center_2000m', 'POIs_education_area_50m', 'POIs_education_area_200m', 'POIs_education_area_300m', 'POIs_education_area_500m', 'POIs_education_area_1000m', 'POIs_education_area_2000m', 'POIs_competitors_50m', 'POIs_competitors_200m', 'POIs_competitors_300m', 'POIs_competitors_500m', 'POIs_competitors_1000m', 'POIs_competitors_2000m', 'main_profile_NDF', 'main_profile_คมนาคมสาธารณะ', 'main_profile_ที่พักอาศัย/ตลาด', 'main_profile_ปั๊มน้ำมัน', 'main_profile_สถานที่ท่องเที่ยว', 'main_profile_สถานบันเทิง', 'main_profile_สถานศึกษา', 'main_profile_สำนักงาน', 'main_profile_โรงงาน', 'main_profile_โรงพยาบาล', 'sub_profile_NDF', 'sub_profile_คมนาคมสาธารณะ', 'sub_profile_ที่พักอาศัย/ตลาด', 'sub_profile_ปั๊มน้ำมัน', 'sub_profile_สถานบันเทิง', 'sub_profile_สถานศึกษา', 'sub_profile_สำนักงาน', 'sub_profile_โรงงาน', 'sub_profile_โรงพยาบาล', 'strategic_location_4 เหล่าทัพ', 'strategic_location_Community/MiniMall/ห้างสรรพสินค้า', 'strategic_location_NDF', 'strategic_location_Office Building', 'strategic_location_การเคหะ', 'strategic_location_คอนโด (เซ็นสัญญากลุ่ม)', 'strategic_location_คอนโด (เซ็นสัญญาเดี่ยว)', 'strategic_location_ทำเลพิเศษอื่นๆ', 'strategic_location_ที่อยู่อาศัย เฉพาะเซ็นสัญญากลุ่ม (BSP)', 'strategic_location_มหาวิทยาลัย/ราชภัฏ/วิทยาลัย/เทคนิค', 'strategic_location_สนามบิน', 'strategic_location_แนวรถไฟฟ้า', 'strategic_location_โรงงาน/นิคมอุตสาหกรรม', 'strategic_location_โรงพยาบาลชั้นหนึ่ง รัฐบาล/เอกชน', 'strategic_location_โรงเรียนประถม-มัธยมประจำจังหวัด', 'strategic_location_ไม่ใช่ Strategic Location', 'CRO_store_type_BU', 'CRO_store_type_Booth', 'CRO_store_type_SA', 'CRO_store_type_SH', 'CRO_store_franchise_Co', 'CRO_store_franchise_PTTOR', 'CRO_store_franchise_SBP', 'open_month', 'y_nor', 'green_wkday_12_cr_0', 'green_wkday_12_cr_1', 'green_wkday_12_cr_2', 'green_wkday_12_cr_3', 'green_wkday_12_cr_4', 'green_wkday_12_cr_5', 'green_wkday_12_cr_6', 'green_wkday_12_cr_7', 'orange_wkday_12_cr_0', 'orange_wkday_12_cr_1', 'orange_wkday_12_cr_2', 'orange_wkday_12_cr_3', 'orange_wkday_12_cr_4', 'orange_wkday_12_cr_5', 'orange_wkday_12_cr_6', 'orange_wkday_12_cr_7', 'red_wkday_12_cr_0', 'red_wkday_12_cr_1', 'red_wkday_12_cr_2', 'red_wkday_12_cr_3', 'red_wkday_12_cr_4', 'red_wkday_12_cr_5', 'red_wkday_12_cr_6', 'red_wkday_12_cr_7', 'maroon_wkday_12_cr_0', 'maroon_wkday_12_cr_1', 'maroon_wkday_12_cr_2', 'maroon_wkday_12_cr_3', 'maroon_wkday_12_cr_4', 'maroon_wkday_12_cr_5', 'maroon_wkday_12_cr_6', 'maroon_wkday_12_cr_7', 'green_wkday_18_cr_0', 'green_wkday_18_cr_1', 'green_wkday_18_cr_2', 'green_wkday_18_cr_3', 'green_wkday_18_cr_4', 'green_wkday_18_cr_5', 'green_wkday_18_cr_6', 'green_wkday_18_cr_7', 'orange_wkday_18_cr_0', 'orange_wkday_18_cr_1', 'orange_wkday_18_cr_2', 'orange_wkday_18_cr_3', 'orange_wkday_18_cr_4', 'orange_wkday_18_cr_5', 'orange_wkday_18_cr_6', 'orange_wkday_18_cr_7', 'red_wkday_18_cr_0', 'red_wkday_18_cr_1', 'red_wkday_18_cr_2', 'red_wkday_18_cr_3', 'red_wkday_18_cr_4', 'red_wkday_18_cr_5', 'red_wkday_18_cr_6', 'red_wkday_18_cr_7', 'maroon_wkday_18_cr_0', 'maroon_wkday_18_cr_1', 'maroon_wkday_18_cr_2', 'maroon_wkday_18_cr_3', 'maroon_wkday_18_cr_4', 'maroon_wkday_18_cr_5', 'maroon_wkday_18_cr_6', 'maroon_wkday_18_cr_7', 'green_wkend_12_cr_0', 'green_wkend_12_cr_1', 'green_wkend_12_cr_2', 'green_wkend_12_cr_3', 'green_wkend_12_cr_4', 'green_wkend_12_cr_5', 'green_wkend_12_cr_6', 'green_wkend_12_cr_7', 'orange_wkend_12_cr_0', 'orange_wkend_12_cr_1', 'orange_wkend_12_cr_2', 'orange_wkend_12_cr_3', 'orange_wkend_12_cr_4', 'orange_wkend_12_cr_5', 'orange_wkend_12_cr_6', 'orange_wkend_12_cr_7', 'red_wkend_12_cr_0', 'red_wkend_12_cr_1', 'red_wkend_12_cr_2', 'red_wkend_12_cr_3', 'red_wkend_12_cr_4', 'red_wkend_12_cr_5', 'red_wkend_12_cr_6', 'red_wkend_12_cr_7', 'maroon_wkend_12_cr_0', 'maroon_wkend_12_cr_1', 'maroon_wkend_12_cr_2', 'maroon_wkend_12_cr_3', 'maroon_wkend_12_cr_4', 'maroon_wkend_12_cr_5', 'maroon_wkend_12_cr_6', 'maroon_wkend_12_cr_7', 'green_wkend_18_cr_0', 'green_wkend_18_cr_1', 'green_wkend_18_cr_2', 'green_wkend_18_cr_3', 'green_wkend_18_cr_4', 'green_wkend_18_cr_5', 'green_wkend_18_cr_6', 'green_wkend_18_cr_7', 'orange_wkend_18_cr_0', 'orange_wkend_18_cr_1', 'orange_wkend_18_cr_2', 'orange_wkend_18_cr_3', 'orange_wkend_18_cr_4', 'orange_wkend_18_cr_5', 'orange_wkend_18_cr_6', 'orange_wkend_18_cr_7', 'red_wkend_18_cr_0', 'red_wkend_18_cr_1', 'red_wkend_18_cr_2', 'red_wkend_18_cr_3', 'red_wkend_18_cr_4', 'red_wkend_18_cr_5', 'red_wkend_18_cr_6', 'red_wkend_18_cr_7', 'maroon_wkend_18_cr_0', 'maroon_wkend_18_cr_1', 'maroon_wkend_18_cr_2', 'maroon_wkend_18_cr_3', 'maroon_wkend_18_cr_4', 'maroon_wkend_18_cr_5', 'maroon_wkend_18_cr_6', 'maroon_wkend_18_cr_7', 'road_length_path_cr_0', 'road_length_path_cr_1', 'road_length_path_cr_2', 'road_length_path_cr_3', 'road_length_path_cr_4', 'road_length_path_cr_5', 'road_length_path_cr_6', 'road_length_path_cr_7', 'road_length_bus_stop_cr_0', 'road_length_bus_stop_cr_1', 'road_length_bus_stop_cr_2', 'road_length_bus_stop_cr_3', 'road_length_bus_stop_cr_4', 'road_length_bus_stop_cr_5', 'road_length_bus_stop_cr_6', 'road_length_bus_stop_cr_7', 'road_length_track_cr_0', 'road_length_track_cr_1', 'road_length_track_cr_2', 'road_length_track_cr_3', 'road_length_track_cr_4', 'road_length_track_cr_5', 'road_length_track_cr_6', 'road_length_track_cr_7', 'road_length_trunk_cr_0', 'road_length_trunk_cr_1', 'road_length_trunk_cr_2', 'road_length_trunk_cr_3', 'road_length_trunk_cr_4', 'road_length_trunk_cr_5', 'road_length_trunk_cr_6', 'road_length_trunk_cr_7', 'road_length_primary_cr_0', 'road_length_primary_cr_1', 'road_length_primary_cr_2', 'road_length_primary_cr_3', 'road_length_primary_cr_4', 'road_length_primary_cr_5', 'road_length_primary_cr_6', 'road_length_primary_cr_7', 'road_length_footway_cr_0', 'road_length_footway_cr_1', 'road_length_footway_cr_2', 'road_length_footway_cr_3', 'road_length_footway_cr_4', 'road_length_footway_cr_5', 'road_length_footway_cr_6', 'road_length_footway_cr_7', 'road_length_secondary_cr_0', 'road_length_secondary_cr_1', 'road_length_secondary_cr_2', 'road_length_secondary_cr_3', 'road_length_secondary_cr_4', 'road_length_secondary_cr_5', 'road_length_secondary_cr_6', 'road_length_secondary_cr_7', 'road_length_tertiary_cr_0', 'road_length_tertiary_cr_1', 'road_length_tertiary_cr_2', 'road_length_tertiary_cr_3', 'road_length_tertiary_cr_4', 'road_length_tertiary_cr_5', 'road_length_tertiary_cr_6', 'road_length_tertiary_cr_7', 'road_length_unclassified_cr_0', 'road_length_unclassified_cr_1', 'road_length_unclassified_cr_2', 'road_length_unclassified_cr_3', 'road_length_unclassified_cr_4', 'road_length_unclassified_cr_5', 'road_length_unclassified_cr_6', 'road_length_unclassified_cr_7', 'road_length_service_cr_0', 'road_length_service_cr_1', 'road_length_service_cr_2', 'road_length_service_cr_3', 'road_length_service_cr_4', 'road_length_service_cr_5', 'road_length_service_cr_6', 'road_length_service_cr_7', 'road_length_residential_cr_0', 'road_length_residential_cr_1', 'road_length_residential_cr_2', 'road_length_residential_cr_3', 'road_length_residential_cr_4', 'road_length_residential_cr_5', 'road_length_residential_cr_6', 'road_length_residential_cr_7', 'prov_namt_กรุงเทพมหานคร', 'prov_namt_ปทุมธานี', 'store_franchise_Co', 'store_franchise_SBP', 'subset', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7', 'embedding_8', 'embedding_9', 'embedding_10', 'embedding_11', 'embedding_12', 'embedding_13', 'embedding_14', 'embedding_15', 'embedding_16', 'embedding_17', 'embedding_18', 'embedding_19', 'embedding_20', 'embedding_21', 'embedding_22', 'embedding_23', 'embedding_24', 'embedding_25', 'embedding_26', 'embedding_27', 'embedding_28', 'embedding_29', 'embedding_30', 'embedding_31', 'embedding_32', 'embedding_33', 'embedding_34', 'embedding_35', 'embedding_36', 'embedding_37', 'embedding_38', 'embedding_39', 'embedding_40', 'embedding_41', 'embedding_42', 'embedding_43', 'embedding_44', 'embedding_45', 'embedding_46', 'embedding_47', 'embedding_48', 'embedding_49', 'embedding_50', 'embedding_51', 'embedding_52', 'embedding_53', 'embedding_54', 'embedding_55', 'embedding_56', 'embedding_57', 'embedding_58', 'embedding_59', 'embedding_60', 'embedding_61', 'embedding_62', 'embedding_63', 'embedding_64', 'embedding_65', 'embedding_66', 'embedding_67', 'embedding_68', 'embedding_69', 'embedding_70', 'embedding_71', 'embedding_72', 'embedding_73', 'embedding_74', 'embedding_75', 'embedding_76', 'embedding_77', 'embedding_78', 'embedding_79', 'embedding_80', 'embedding_81', 'embedding_82', 'embedding_83', 'embedding_84', 'embedding_85', 'embedding_86', 'embedding_87', 'embedding_88', 'embedding_89', 'embedding_90', 'embedding_91', 'embedding_92', 'embedding_93', 'embedding_94', 'embedding_95', 'embedding_96', 'embedding_97', 'embedding_98', 'embedding_99', 'embedding_100', 'embedding_101', 'embedding_102', 'embedding_103', 'embedding_104', 'embedding_105', 'embedding_106', 'embedding_107', 'embedding_108', 'embedding_109', 'embedding_110', 'embedding_111', 'embedding_112', 'embedding_113', 'embedding_114', 'embedding_115', 'embedding_116', 'embedding_117', 'embedding_118', 'embedding_119', 'embedding_120', 'embedding_121', 'embedding_122', 'embedding_123', 'embedding_124', 'embedding_125', 'embedding_126', 'embedding_127', 'embedding_128', 'embedding_129', 'embedding_130', 'embedding_131', 'embedding_132', 'embedding_133', 'embedding_134', 'embedding_135', 'embedding_136', 'embedding_137', 'embedding_138', 'embedding_139', 'embedding_140', 'embedding_141', 'embedding_142', 'embedding_143', 'embedding_144', 'embedding_145', 'embedding_146', 'embedding_147', 'embedding_148', 'embedding_149', 'embedding_150', 'embedding_151', 'embedding_152', 'embedding_153', 'embedding_154', 'embedding_155', 'embedding_156', 'embedding_157', 'embedding_158', 'embedding_159', 'embedding_160', 'embedding_161', 'embedding_162', 'embedding_163', 'embedding_164', 'embedding_165', 'embedding_166', 'embedding_167', 'embedding_168', 'embedding_169', 'embedding_170', 'embedding_171', 'embedding_172', 'embedding_173', 'embedding_174', 'embedding_175', 'embedding_176', 'embedding_177', 'embedding_178', 'embedding_179', 'embedding_180', 'embedding_181', 'embedding_182', 'embedding_183', 'embedding_184', 'embedding_185', 'embedding_186', 'embedding_187', 'embedding_188', 'embedding_189', 'embedding_190', 'embedding_191', 'embedding_192', 'embedding_193', 'embedding_194', 'embedding_195', 'embedding_196', 'embedding_197', 'embedding_198', 'embedding_199', 'embedding_200', 'embedding_201', 'embedding_202', 'embedding_203', 'embedding_204', 'embedding_205', 'embedding_206', 'embedding_207', 'embedding_208', 'embedding_209', 'embedding_210', 'embedding_211', 'embedding_212', 'embedding_213', 'embedding_214', 'embedding_215', 'embedding_216', 'embedding_217', 'embedding_218', 'embedding_219', 'embedding_220', 'embedding_221', 'embedding_222', 'embedding_223', 'embedding_224', 'embedding_225', 'embedding_226', 'embedding_227', 'embedding_228', 'embedding_229', 'embedding_230', 'embedding_231', 'embedding_232', 'embedding_233', 'embedding_234', 'embedding_235', 'embedding_236', 'embedding_237', 'embedding_238', 'embedding_239', 'embedding_240', 'embedding_241', 'embedding_242', 'embedding_243', 'embedding_244', 'embedding_245', 'embedding_246', 'embedding_247', 'embedding_248', 'embedding_249', 'embedding_250', 'embedding_251', 'embedding_252', 'embedding_253', 'embedding_254', 'embedding_255', 'embedding_256', 'embedding_257', 'embedding_258', 'embedding_259', 'embedding_260', 'embedding_261', 'embedding_262', 'embedding_263', 'embedding_264', 'embedding_265', 'embedding_266', 'embedding_267', 'embedding_268', 'embedding_269', 'embedding_270', 'embedding_271', 'embedding_272', 'embedding_273', 'embedding_274', 'embedding_275', 'embedding_276', 'embedding_277', 'embedding_278', 'embedding_279', 'embedding_280', 'embedding_281', 'embedding_282', 'embedding_283', 'embedding_284', 'embedding_285', 'embedding_286', 'embedding_287', 'embedding_288', 'embedding_289', 'embedding_290', 'embedding_291', 'embedding_292', 'embedding_293', 'embedding_294', 'embedding_295', 'embedding_296', 'embedding_297', 'embedding_298', 'embedding_299', 'embedding_300', 'embedding_301', 'embedding_302', 'embedding_303', 'embedding_304', 'embedding_305', 'embedding_306', 'embedding_307', 'embedding_308', 'embedding_309', 'embedding_310', 'embedding_311', 'embedding_312', 'embedding_313', 'embedding_314', 'embedding_315', 'embedding_316', 'embedding_317', 'embedding_318', 'embedding_319', 'embedding_320', 'embedding_321', 'embedding_322', 'embedding_323', 'embedding_324', 'embedding_325', 'embedding_326', 'embedding_327', 'embedding_328', 'embedding_329', 'embedding_330', 'embedding_331', 'embedding_332', 'embedding_333', 'embedding_334', 'embedding_335', 'embedding_336', 'embedding_337', 'embedding_338', 'embedding_339', 'embedding_340', 'embedding_341', 'embedding_342', 'embedding_343', 'embedding_344', 'embedding_345', 'embedding_346', 'embedding_347', 'embedding_348', 'embedding_349', 'embedding_350', 'embedding_351', 'embedding_352', 'embedding_353', 'embedding_354', 'embedding_355', 'embedding_356', 'embedding_357', 'embedding_358', 'embedding_359', 'embedding_360', 'embedding_361', 'embedding_362', 'embedding_363', 'embedding_364', 'embedding_365', 'embedding_366', 'embedding_367', 'embedding_368', 'embedding_369', 'embedding_370', 'embedding_371', 'embedding_372', 'embedding_373', 'embedding_374', 'embedding_375', 'embedding_376', 'embedding_377', 'embedding_378', 'embedding_379', 'embedding_380', 'embedding_381', 'embedding_382', 'embedding_383', 'embedding_384', 'embedding_385', 'embedding_386', 'embedding_387', 'embedding_388', 'embedding_389', 'embedding_390', 'embedding_391', 'embedding_392', 'embedding_393', 'embedding_394', 'embedding_395', 'embedding_396', 'embedding_397', 'embedding_398', 'embedding_399', 'embedding_400', 'embedding_401', 'embedding_402', 'embedding_403', 'embedding_404', 'embedding_405', 'embedding_406', 'embedding_407', 'embedding_408', 'embedding_409', 'embedding_410', 'embedding_411', 'embedding_412', 'embedding_413', 'embedding_414', 'embedding_415', 'embedding_416', 'embedding_417', 'embedding_418', 'embedding_419', 'embedding_420', 'embedding_421', 'embedding_422', 'embedding_423', 'embedding_424', 'embedding_425', 'embedding_426', 'embedding_427', 'embedding_428', 'embedding_429', 'embedding_430', 'embedding_431', 'embedding_432', 'embedding_433', 'embedding_434', 'embedding_435', 'embedding_436', 'embedding_437', 'embedding_438', 'embedding_439', 'embedding_440', 'embedding_441', 'embedding_442', 'embedding_443', 'embedding_444', 'embedding_445', 'embedding_446', 'embedding_447', 'embedding_448', 'embedding_449', 'embedding_450', 'embedding_451', 'embedding_452', 'embedding_453', 'embedding_454', 'embedding_455', 'embedding_456', 'embedding_457', 'embedding_458', 'embedding_459', 'embedding_460', 'embedding_461', 'embedding_462', 'embedding_463', 'embedding_464', 'embedding_465', 'embedding_466', 'embedding_467', 'embedding_468', 'embedding_469', 'embedding_470', 'embedding_471', 'embedding_472', 'embedding_473', 'embedding_474', 'embedding_475', 'embedding_476', 'embedding_477', 'embedding_478', 'embedding_479', 'embedding_480', 'embedding_481', 'embedding_482', 'embedding_483', 'embedding_484', 'embedding_485', 'embedding_486', 'embedding_487', 'embedding_488', 'embedding_489', 'embedding_490', 'embedding_491', 'embedding_492', 'embedding_493', 'embedding_494', 'embedding_495', 'embedding_496', 'embedding_497', 'embedding_498', 'embedding_499', 'embedding_500', 'embedding_501', 'embedding_502', 'embedding_503', 'embedding_504', 'embedding_505', 'embedding_506', 'embedding_507', 'embedding_508', 'embedding_509', 'embedding_510', 'embedding_511', 'embedding_512']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_nor\n"
     ]
    }
   ],
   "source": [
    "# check is it has y_nor df.columns\n",
    "if \"y_nor\" in df.columns:\n",
    "    print(\"y_nor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use embedding to predict mockup_sale with xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# get all column has embedding_ prefix\n",
    "# feature_columns = [col for col in df.columns if col.startswith(\"embedding_\")]\n",
    "# feature_columns += [\"subset\"]\n",
    "# feature_columns += [\"y_nor\"]\n",
    "# assign to x\n",
    "# all_data = df[feature_columns]\n",
    "all_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>sum_pop_in_voronoi</th>\n",
       "      <th>voronoi_area</th>\n",
       "      <th>voronoi_density</th>\n",
       "      <th>cro_open_year</th>\n",
       "      <th>CRO_store_length</th>\n",
       "      <th>CRO_store_parking</th>\n",
       "      <th>CRO_store_stock_area</th>\n",
       "      <th>CRO_store_total_area</th>\n",
       "      <th>CRO_store_width</th>\n",
       "      <th>...</th>\n",
       "      <th>road_length_residential_cr_3</th>\n",
       "      <th>road_length_residential_cr_4</th>\n",
       "      <th>road_length_residential_cr_5</th>\n",
       "      <th>road_length_residential_cr_6</th>\n",
       "      <th>road_length_residential_cr_7</th>\n",
       "      <th>prov_namt_กรุงเทพมหานคร</th>\n",
       "      <th>prov_namt_ปทุมธานี</th>\n",
       "      <th>store_franchise_Co</th>\n",
       "      <th>store_franchise_SBP</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1025.0</td>\n",
       "      <td>16369.32</td>\n",
       "      <td>38412.2</td>\n",
       "      <td>0.426149</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.39</td>\n",
       "      <td>274.39</td>\n",
       "      <td>14.00</td>\n",
       "      <td>...</td>\n",
       "      <td>77.783004</td>\n",
       "      <td>84.454770</td>\n",
       "      <td>92.006420</td>\n",
       "      <td>120.813019</td>\n",
       "      <td>137.299551</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8396.0</td>\n",
       "      <td>15736.69</td>\n",
       "      <td>241705.5</td>\n",
       "      <td>0.065107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.86</td>\n",
       "      <td>175.86</td>\n",
       "      <td>19.80</td>\n",
       "      <td>...</td>\n",
       "      <td>157.117009</td>\n",
       "      <td>156.780832</td>\n",
       "      <td>163.828702</td>\n",
       "      <td>144.524316</td>\n",
       "      <td>153.055289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8572.0</td>\n",
       "      <td>16156.14</td>\n",
       "      <td>193980.1</td>\n",
       "      <td>0.083288</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.90</td>\n",
       "      <td>145.90</td>\n",
       "      <td>17.80</td>\n",
       "      <td>...</td>\n",
       "      <td>88.553455</td>\n",
       "      <td>86.053817</td>\n",
       "      <td>66.272860</td>\n",
       "      <td>73.498362</td>\n",
       "      <td>69.179231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1058.0</td>\n",
       "      <td>11213.96</td>\n",
       "      <td>77343.2</td>\n",
       "      <td>0.144990</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.83</td>\n",
       "      <td>93.83</td>\n",
       "      <td>7.90</td>\n",
       "      <td>...</td>\n",
       "      <td>145.375304</td>\n",
       "      <td>151.805544</td>\n",
       "      <td>163.678876</td>\n",
       "      <td>90.233285</td>\n",
       "      <td>123.416384</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>16216.47</td>\n",
       "      <td>90980.3</td>\n",
       "      <td>0.178242</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.18</td>\n",
       "      <td>113.18</td>\n",
       "      <td>7.94</td>\n",
       "      <td>...</td>\n",
       "      <td>129.253148</td>\n",
       "      <td>178.432519</td>\n",
       "      <td>189.934764</td>\n",
       "      <td>143.326666</td>\n",
       "      <td>133.012108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id  sum_pop_in_voronoi  voronoi_area  voronoi_density  cro_open_year  \\\n",
       "0    1025.0            16369.32       38412.2         0.426149           16.0   \n",
       "1    8396.0            15736.69      241705.5         0.065107           16.0   \n",
       "2    8572.0            16156.14      193980.1         0.083288           16.0   \n",
       "3    1058.0            11213.96       77343.2         0.144990           16.0   \n",
       "4    1095.0            16216.47       90980.3         0.178242           16.0   \n",
       "\n",
       "   CRO_store_length  CRO_store_parking  CRO_store_stock_area  \\\n",
       "0             20.00                0.0                 97.39   \n",
       "1             15.35                0.0                 44.86   \n",
       "2              9.85                0.0                 12.90   \n",
       "3             13.94                0.0                 11.83   \n",
       "4             15.82                0.0                 35.18   \n",
       "\n",
       "   CRO_store_total_area  CRO_store_width  ...  road_length_residential_cr_3  \\\n",
       "0                274.39            14.00  ...                     77.783004   \n",
       "1                175.86            19.80  ...                    157.117009   \n",
       "2                145.90            17.80  ...                     88.553455   \n",
       "3                 93.83             7.90  ...                    145.375304   \n",
       "4                113.18             7.94  ...                    129.253148   \n",
       "\n",
       "   road_length_residential_cr_4  road_length_residential_cr_5  \\\n",
       "0                     84.454770                     92.006420   \n",
       "1                    156.780832                    163.828702   \n",
       "2                     86.053817                     66.272860   \n",
       "3                    151.805544                    163.678876   \n",
       "4                    178.432519                    189.934764   \n",
       "\n",
       "   road_length_residential_cr_6  road_length_residential_cr_7  \\\n",
       "0                    120.813019                    137.299551   \n",
       "1                    144.524316                    153.055289   \n",
       "2                     73.498362                     69.179231   \n",
       "3                     90.233285                    123.416384   \n",
       "4                    143.326666                    133.012108   \n",
       "\n",
       "   prov_namt_กรุงเทพมหานคร  prov_namt_ปทุมธานี  store_franchise_Co  \\\n",
       "0                        1                   0                   0   \n",
       "1                        1                   0                   0   \n",
       "2                        1                   0                   1   \n",
       "3                        0                   1                   1   \n",
       "4                        1                   0                   1   \n",
       "\n",
       "   store_franchise_SBP  subset  \n",
       "0                    1   train  \n",
       "1                    1   train  \n",
       "2                    0   train  \n",
       "3                    0   train  \n",
       "4                    0   train  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove column startswith embedding_\n",
    "all_data = all_data.loc[:, ~all_data.columns.str.startswith(\"embedding_\")]\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"y_nor\" not in all_data.columns:\n",
    "    print(\"y_nor\")\n",
    "if \"store_id\" not in all_data.columns:\n",
    "    print(\"store_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_pop_in_voronoi</th>\n",
       "      <th>voronoi_area</th>\n",
       "      <th>voronoi_density</th>\n",
       "      <th>cro_open_year</th>\n",
       "      <th>CRO_store_length</th>\n",
       "      <th>CRO_store_parking</th>\n",
       "      <th>CRO_store_stock_area</th>\n",
       "      <th>CRO_store_total_area</th>\n",
       "      <th>CRO_store_width</th>\n",
       "      <th>CRO_store_shophouse_blocks</th>\n",
       "      <th>...</th>\n",
       "      <th>road_length_residential_cr_5</th>\n",
       "      <th>road_length_residential_cr_6</th>\n",
       "      <th>road_length_residential_cr_7</th>\n",
       "      <th>prov_namt_กรุงเทพมหานคร</th>\n",
       "      <th>prov_namt_ปทุมธานี</th>\n",
       "      <th>store_franchise_Co</th>\n",
       "      <th>store_franchise_SBP</th>\n",
       "      <th>y_nor</th>\n",
       "      <th>subset</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809053</td>\n",
       "      <td>-0.435626</td>\n",
       "      <td>1.276019</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>1.119992</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>1.958702</td>\n",
       "      <td>1.316572</td>\n",
       "      <td>-0.099400</td>\n",
       "      <td>1.694327</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.012147</td>\n",
       "      <td>-0.368337</td>\n",
       "      <td>0.022957</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>-0.419156</td>\n",
       "      <td>-0.960848</td>\n",
       "      <td>1.091138</td>\n",
       "      <td>0.226238</td>\n",
       "      <td>train</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.587070</td>\n",
       "      <td>-0.246327</td>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-0.168104</td>\n",
       "      <td>-0.166140</td>\n",
       "      <td>0.836214</td>\n",
       "      <td>1.078724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513163</td>\n",
       "      <td>0.147987</td>\n",
       "      <td>0.375884</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>-0.419156</td>\n",
       "      <td>-0.960848</td>\n",
       "      <td>1.091138</td>\n",
       "      <td>0.182798</td>\n",
       "      <td>train</td>\n",
       "      <td>8396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734251</td>\n",
       "      <td>-0.290767</td>\n",
       "      <td>-0.193664</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>-1.067295</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-1.462083</td>\n",
       "      <td>-0.616988</td>\n",
       "      <td>0.513588</td>\n",
       "      <td>-0.768087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.558658</td>\n",
       "      <td>-1.398633</td>\n",
       "      <td>-1.502935</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>-0.419156</td>\n",
       "      <td>1.040748</td>\n",
       "      <td>-0.916474</td>\n",
       "      <td>0.433002</td>\n",
       "      <td>train</td>\n",
       "      <td>8572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.999912</td>\n",
       "      <td>-0.399375</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>-0.185915</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-1.505405</td>\n",
       "      <td>-1.400555</td>\n",
       "      <td>-1.083407</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509981</td>\n",
       "      <td>-1.034223</td>\n",
       "      <td>-0.288025</td>\n",
       "      <td>-2.385745</td>\n",
       "      <td>2.385745</td>\n",
       "      <td>1.040748</td>\n",
       "      <td>-0.916474</td>\n",
       "      <td>0.221966</td>\n",
       "      <td>train</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755420</td>\n",
       "      <td>-0.386677</td>\n",
       "      <td>0.213359</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-0.560023</td>\n",
       "      <td>-1.109370</td>\n",
       "      <td>-1.076954</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067585</td>\n",
       "      <td>0.121908</td>\n",
       "      <td>-0.073082</td>\n",
       "      <td>0.419156</td>\n",
       "      <td>-0.419156</td>\n",
       "      <td>1.040748</td>\n",
       "      <td>-0.916474</td>\n",
       "      <td>0.149573</td>\n",
       "      <td>train</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_pop_in_voronoi  voronoi_area  voronoi_density  cro_open_year  \\\n",
       "0            0.809053     -0.435626         1.276019      -0.585552   \n",
       "1            0.587070     -0.246327        -0.271598      -0.585552   \n",
       "2            0.734251     -0.290767        -0.193664      -0.585552   \n",
       "3           -0.999912     -0.399375         0.070823      -0.585552   \n",
       "4            0.755420     -0.386677         0.213359      -0.585552   \n",
       "\n",
       "   CRO_store_length  CRO_store_parking  CRO_store_stock_area  \\\n",
       "0          1.119992           -0.60246              1.958702   \n",
       "1          0.117934           -0.60246             -0.168104   \n",
       "2         -1.067295           -0.60246             -1.462083   \n",
       "3         -0.185915           -0.60246             -1.505405   \n",
       "4          0.219217           -0.60246             -0.560023   \n",
       "\n",
       "   CRO_store_total_area  CRO_store_width  CRO_store_shophouse_blocks  ...  \\\n",
       "0              1.316572        -0.099400                    1.694327  ...   \n",
       "1             -0.166140         0.836214                    1.078724  ...   \n",
       "2             -0.616988         0.513588                   -0.768087  ...   \n",
       "3             -1.400555        -1.083407                    0.463120  ...   \n",
       "4             -1.109370        -1.076954                    0.463120  ...   \n",
       "\n",
       "   road_length_residential_cr_5  road_length_residential_cr_6  \\\n",
       "0                     -1.012147                     -0.368337   \n",
       "1                      0.513163                      0.147987   \n",
       "2                     -1.558658                     -1.398633   \n",
       "3                      0.509981                     -1.034223   \n",
       "4                      1.067585                      0.121908   \n",
       "\n",
       "   road_length_residential_cr_7  prov_namt_กรุงเทพมหานคร  prov_namt_ปทุมธานี  \\\n",
       "0                      0.022957                 0.419156           -0.419156   \n",
       "1                      0.375884                 0.419156           -0.419156   \n",
       "2                     -1.502935                 0.419156           -0.419156   \n",
       "3                     -0.288025                -2.385745            2.385745   \n",
       "4                     -0.073082                 0.419156           -0.419156   \n",
       "\n",
       "   store_franchise_Co  store_franchise_SBP     y_nor  subset  store_id  \n",
       "0           -0.960848             1.091138  0.226238   train      1025  \n",
       "1           -0.960848             1.091138  0.182798   train      8396  \n",
       "2            1.040748            -0.916474  0.433002   train      8572  \n",
       "3            1.040748            -0.916474  0.221966   train      1058  \n",
       "4            1.040748            -0.916474  0.149573   train      1095  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming all_data is a pandas DataFrame\n",
    "all_data = all_data.drop(columns=[\"y_nor\"])\n",
    "\n",
    "# Separate the training data for normalization\n",
    "train_all_data = all_data[all_data.subset == \"train\"]\n",
    "train_store_ids = train_all_data[\"store_id\"]\n",
    "\n",
    "# Drop unnecessary columns for normalization\n",
    "all_data = all_data.drop(columns=[\"subset\", \"store_id\"])\n",
    "\n",
    "# Normalize the remaining columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_all_data.drop(columns=[\"subset\", \"store_id\"]))\n",
    "all_data_normalized = scaler.transform(all_data)\n",
    "all_data_normalized = pd.DataFrame(all_data_normalized, columns=all_data.columns)\n",
    "\n",
    "# Add back the store_id column\n",
    "all_data_normalized[\"y_nor\"] = df[\"y_nor\"]\n",
    "all_data_normalized[\"subset\"] = df[\"subset\"]\n",
    "all_data_normalized[\"store_id\"] = df[\"store_id\"]\n",
    "\n",
    "# If needed, convert store_id back to its original data type\n",
    "all_data_normalized[\"store_id\"] = all_data_normalized[\"store_id\"].astype(int)\n",
    "all_data = all_data_normalized.copy()\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train test with columns subset\n",
    "x_train = all_data[all_data.subset == \"train\"]\n",
    "x_train = x_train.drop(columns=[\"subset\"])\n",
    "y_train = x_train[\"y_nor\"]\n",
    "x_test = all_data[all_data.subset == \"test\"]\n",
    "x_test = x_test.drop(columns=[\"subset\"])\n",
    "y_test = x_test[\"y_nor\"]\n",
    "x_train = x_train.drop(columns=[\"y_nor\"])\n",
    "x_test = x_test.drop(columns=[\"y_nor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((977, 383), (977,))"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_percentage_error: 1.076031445276195\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an XGBoost regressor\n",
    "regressor = xgb.XGBRegressor(objective=\"reg:squarederror\", seed=42)\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"mean_absolute_percentage_error: {mape}\")\n",
    "\n",
    "# Plot the results\n",
    "# plt.scatter(x_test, y_test, color=\"black\", label=\"Actual\")\n",
    "plt.scatter(y_test, y_pred, color=\"red\", label=\"Predicted\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"XGBoost Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\n",
    "            \"MPS not available because the current PyTorch install was not \"\n",
    "            \"built with MPS enabled.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "            \"and/or you do not have an MPS-enabled device on this machine.\"\n",
    "        )\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are NumPy arrays\n",
    "X_train = np.array(x_train)\n",
    "X_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Extract store_id column from X_train, X_val, and X_test\n",
    "store_id_train = X_train[:, -1]\n",
    "store_id_val = X_val[:, -1]\n",
    "store_id_test = X_test[:, -1]\n",
    "\n",
    "\n",
    "# Remove store_id column from X_train, X_val, and X_test\n",
    "X_train = X_train[:, :-1]\n",
    "X_val = X_val[:, :-1]\n",
    "X_test = X_test[:, :-1]\n",
    "\n",
    "\n",
    "# Now, you have X_train_without_store_id, X_val_without_store_id, and X_test_without_store_id\n",
    "# without the store_id column, and store_id_train, store_id_val, and store_id_test with only the store_id column\n",
    "\n",
    "# If needed, convert store_id_train to its original data type\n",
    "store_id_train = store_id_train.astype(int)\n",
    "store_id_val = store_id_val.astype(int)\n",
    "store_id_test = store_id_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781, 382)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((781,), (196,), (68,))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_id_train.shape, store_id_val.shape, store_id_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | image_model | MaxxVit    | 30.5 M\n",
      "1 | layers      | ModuleList | 135 K \n",
      "2 | layer_norms | ModuleList | 834   \n",
      "3 | dropouts    | ModuleList | 0     \n",
      "-------------------------------------------\n",
      "30.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.7 M    Total params\n",
      "122.690   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b867c08d6243b3931fd55e55eacca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdf3c45e37b438fa0782eca0cc1ec73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7f00de4d7140eb92342e1c7f21c267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb35511f7a04466acb97e6875f76ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8536c2216cb74ec699c4842e8227b3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ddc8ef8a7f4814890962bf12d50b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb37f34510d34e22a31b21fb5508bd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e91e9f264b478d907bc2e57789cbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e03aca4d5746abb8b51c072603a5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ef6773e6304254a676f245a63009fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e93e692a8d42c0876381defcbfa8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d7ef157627402992463e7d74e51817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Any\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import lightning as pl\n",
    "from torch.nn import Dropout, BatchNorm1d\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout\n",
    "import timm\n",
    "\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        epsilon = 1e-7\n",
    "        percentage_error = torch.abs((y_true - y_pred) / (y_true + epsilon))\n",
    "        mape = torch.mean(percentage_error) * 100.0\n",
    "        return mape\n",
    "\n",
    "\n",
    "# Define a simple dataset\n",
    "class PriceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        store_ids,\n",
    "        features,\n",
    "        labels,\n",
    "        transform_y=None,\n",
    "        transform_x=None,\n",
    "        transform_image=None,\n",
    "        image_folder=\"/Users/user/Documents/Coding/cro_location_intelligence/notebook/data/crop_image\",\n",
    "    ):\n",
    "        self.image_folder = image_folder\n",
    "        self.store_ids = store_ids\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.transform_y = transform_y\n",
    "        self.transform_x = transform_x\n",
    "        self.transform_image = transform_image\n",
    "        # for idx in range(len(self.features)):\n",
    "        #     image_path = os.path.join(\n",
    "        #         self.image_folder, str(self.store_ids[idx]) + \".png\"\n",
    "        #     )\n",
    "        #     image = Image.open(image_path)\n",
    "\n",
    "        #     # Check if the height is divisible by 16\n",
    "        #     assert (\n",
    "        #         image.size[1] % 16 == 0\n",
    "        #     ), f\"Image height ({image.size[1]}) is not divisible by 16.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        store_id = self.store_ids[idx]\n",
    "        image_path = os.path.join(self.image_folder, str(store_id) + \".png\")\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "        # resize image\n",
    "        desired_height = desired_width = 512\n",
    "        image = image.resize((desired_height, desired_width))\n",
    "        image = transforms.ToTensor()(image)\n",
    "        # image = np.array(image)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform_image:\n",
    "            image = self.transform_image(image)\n",
    "        if self.transform_x:\n",
    "            feature = self.transform_x(feature)\n",
    "\n",
    "        if self.transform_y:\n",
    "            label = self.transform_y(label)\n",
    "\n",
    "        return image, feature, label\n",
    "\n",
    "\n",
    "class PricePredictor(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        image_model_name=\"maxvit_tiny_tf_512.in1k\",\n",
    "        layer_sizes=[],\n",
    "        dropout_rate=0.7,\n",
    "        last_layer_dropout_rate=0.1,\n",
    "        use_batch_norm=True,\n",
    "        lr=0.00001,\n",
    "    ):\n",
    "        super(PricePredictor, self).__init__()\n",
    "\n",
    "        # Image processing model\n",
    "        self.image_model = timm.create_model(\n",
    "            image_model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=0,\n",
    "        ).to(device)\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        # Additional features processing model\n",
    "        layer_sizes = [input_size] + layer_sizes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.layers.append(nn.Linear(layer_sizes[i - 1], layer_sizes[i]))\n",
    "\n",
    "            if use_batch_norm:\n",
    "                self.layer_norms.append(nn.LayerNorm(layer_sizes[i]))\n",
    "\n",
    "            # Use last_layer_dropout_rate for the last layer, otherwise use dropout_rate\n",
    "            if i == len(layer_sizes) - 1:\n",
    "                self.dropouts.append(nn.Dropout(p=last_layer_dropout_rate))\n",
    "            else:\n",
    "                self.dropouts.append(nn.Dropout(p=dropout_rate))\n",
    "\n",
    "        self.lr = lr\n",
    "        self.val_loss = 0\n",
    "        self.training_step_loss = []\n",
    "\n",
    "    def forward(self, image, feature):\n",
    "        # Process image\n",
    "        image_features = self.image_model(image)\n",
    "        image_features = image_features.view(image_features.size(0), -1)\n",
    "\n",
    "        # Process additional features\n",
    "        for i in range(len(self.layers)):\n",
    "            if self.use_batch_norm:\n",
    "                feature = F.leaky_relu(self.layer_norms[i](self.layers[i](feature)))\n",
    "            else:\n",
    "                feature = F.leaky_relu(self.layers[i](feature))\n",
    "\n",
    "            feature = self.dropouts[i](feature)\n",
    "\n",
    "        # Concatenate image and additional features\n",
    "        combined_features = torch.cat([image_features, feature], dim=1)\n",
    "\n",
    "        return combined_features\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, feature, target = batch\n",
    "        output = self(data, feature)\n",
    "        loss = nn.MSELoss()(output.flatten(), target)\n",
    "        self.training_step_loss.append(loss)\n",
    "\n",
    "        # Log the loss on each training step\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        # raise\n",
    "        return loss\n",
    "\n",
    "    # def on_training_epoch_end(self, outputs):\n",
    "    #     # avg_loss = torch.tensor(self.training_step_loss).mean()\n",
    "    #     # self.training_step_loss = []\n",
    "    #     # avg_loss = torch.stack(\n",
    "    #     #     [x.detach().cpu() for x in self.training_step_loss]\n",
    "    #     # ).mean()\n",
    "    #     # self.log(\"train_loss\", avg_loss.item(), on_epoch=True)\n",
    "    #     # print(x)\n",
    "    #     avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "    #     self.log(\"train_loss\", avg_loss.item(), on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, feature, target = batch\n",
    "        output = self(data, feature)\n",
    "        loss = nn.MSELoss()(output.flatten(), target)\n",
    "        self.val_loss = loss\n",
    "\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "from lightning.pytorch.callbacks import LearningRateFinder\n",
    "\n",
    "\n",
    "class FineTuneLearningRateFinder(LearningRateFinder):\n",
    "    def __init__(self, milestones, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.milestones = milestones\n",
    "        self._min_lr = 1e-6\n",
    "        self._max_lr = 1e-1\n",
    "        # self._num_training_steps = 1000\n",
    "        self._mode = \"linear\"\n",
    "\n",
    "    def on_fit_start(self, *args, **kwargs):\n",
    "        return\n",
    "\n",
    "    def on_train_epoch_start(self, trainer, pl_module):\n",
    "        if trainer.current_epoch in self.milestones or trainer.current_epoch == 0:\n",
    "            self.lr_find(trainer, pl_module)\n",
    "\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "class AddNoise(object):\n",
    "    def __init__(self, noise_level=0.01):\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # random apply 20% of the time\n",
    "        if torch.rand(1) < 0.2:\n",
    "            return x\n",
    "        noise = torch.randn_like(x) * self.noise_level\n",
    "        augmented_x = x + noise\n",
    "        return augmented_x\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def salt_and_pepper_noise(image, salt_prob=0.02, pepper_prob=0.02):\n",
    "    \"\"\"\n",
    "    Apply salt-and-pepper noise to the image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: PIL Image\n",
    "    - salt_prob: Probability of adding salt noise\n",
    "    - pepper_prob: Probability of adding pepper noise\n",
    "    \"\"\"\n",
    "    image_array = np.array(image)\n",
    "    height, width, _ = image_array.shape\n",
    "\n",
    "    # Add salt noise\n",
    "    salt_mask = np.random.rand(height, width) < salt_prob\n",
    "    image_array[salt_mask] = 255\n",
    "\n",
    "    # Add pepper noise\n",
    "    pepper_mask = np.random.rand(height, width) < pepper_prob\n",
    "    image_array[pepper_mask] = 0\n",
    "\n",
    "    return Image.fromarray(image_array)\n",
    "\n",
    "\n",
    "desired_height = desired_width = 512\n",
    "transform_image = transforms.Compose(\n",
    "    [\n",
    "        # transforms.Resize((desired_height, desired_width)),\n",
    "        transforms.RandomRotation(degrees=180),  # Random rotation up to 15 degrees\n",
    "        transforms.RandomHorizontalFlip(\n",
    "            p=0.5\n",
    "        ),  # Random horizontal flip with a probability of 0.5\n",
    "        # transforms.Lambda(lambda x: salt_and_pepper_noise(x)),  # Apply salt-and-pepper noise\n",
    "        # transforms.ToTensor(),  # Convert the PIL image to a PyTorch tensor\n",
    "        # Add more transformations if needed, such as normalization\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_x = AddNoise(noise_level=0.1)\n",
    "transforms_y = AddNoise(noise_level=0.025)\n",
    "# batch_size = 16\n",
    "batch_size = 1\n",
    "\n",
    "num_workers = 0\n",
    "train_dataset = PriceDataset(\n",
    "    store_id_train,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    transform_x=transforms_x,\n",
    "    transform_y=transforms_y,\n",
    "    transform_image=transform_image,\n",
    ")\n",
    "test_dataset = PriceDataset(store_id_test, X_test, y_test)\n",
    "val_dataset = PriceDataset(store_id_val, X_val, y_val)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./models/\",\n",
    "    save_top_k=2,\n",
    "    monitor=\"val_loss\",\n",
    "    filename=\"best_model-{epoch}\",\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1:]\n",
    "\n",
    "model = PricePredictor(input_size[0], layer_sizes=[256, 128, 32, 1]).to(device)\n",
    "\n",
    "# model.load_from_checkpoint(check_point_path)\n",
    "\n",
    "\n",
    "# Initialize a PyTorch Lightning Trainer\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0.00, patience=50, verbose=False, mode=\"min\"\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[\n",
    "        # FineTuneLearningRateFinder(\n",
    "        #     milestones=(\n",
    "        #         100,\n",
    "        #         1000,\n",
    "        #         2000,\n",
    "        #         3000,\n",
    "        #         5000,\n",
    "        #         10000,\n",
    "        #     )\n",
    "        # ),\n",
    "        early_stop_callback,\n",
    "        checkpoint_callback,\n",
    "    ],\n",
    "    min_epochs=20000,\n",
    "    max_epochs=30000,\n",
    "    logger=logger,\n",
    "    precision=\"16-mixed\",\n",
    "    accelerator=\"mps\",\n",
    ")\n",
    "# Train the model\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(dataloaders=test_loader)\n",
    "\n",
    "# Make predictionss\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    example_input = torch.tensor(X_test[:5], dtype=torch.float32).to(device)\n",
    "    predictions = model(example_input).flatten().cpu().numpy()\n",
    "\n",
    "print(\"Example Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint at 0x2ceea9910>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/0th_best.pt\n",
      "./models/1th_best.pt\n"
     ]
    }
   ],
   "source": [
    "for i, (path, _) in enumerate(trainer.checkpoint_callback.best_k_models.items()):\n",
    "    model = PricePredictor.load_from_checkpoint(path, input_size=input_size[0])\n",
    "    PATH = f\"./models/{i}th_best.pt\"\n",
    "    torch.save(model, PATH)\n",
    "    print(PATH)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"/Users/user/Documents/Coding/cro_location_intelligence/src/models_version34/best_model-epoch=353.ckpt\"\n",
    "# # model = PricePredictor.load_from_checkpoint(\n",
    "# #     checkpoint_path=checkpoint_path,\n",
    "# #     input_size=input_size[0],\n",
    "# #     use_mps_device=True,\n",
    "# # )\n",
    "# model = torch.load(checkpoint_path)\n",
    "\n",
    "# model.eval()\n",
    "# model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Predictions: [0.2714958  0.26824734 0.39140716 0.30387145 0.21433179 0.1536344\n",
      " 0.17540078 0.18032084 0.24979027 0.22374786 0.22572163 0.2760022\n",
      " 0.21913768 0.3405842  0.26990134 0.24378431 0.19754042 0.28009096\n",
      " 0.24637921 0.36888325 0.2497968  0.28162515 0.20892099 0.17804821\n",
      " 0.2459245  0.21568511 0.2176654  0.18842323 0.24785824 0.21135023\n",
      " 0.17890956 0.19757634 0.18184538 0.27823612 0.19690897 0.22466512\n",
      " 0.23276092 0.2640627  0.25473174 0.21595809 0.2523769  0.21262948\n",
      " 0.28530124 0.23740171 0.23007552 0.21878926 0.25026235]\n",
      "Ground Truth: [ 0.70841744  0.25344402  0.16957017  0.26360735  0.27926378  0.24470932\n",
      "  0.17560358  0.36602374  0.16146888  0.27521046  0.49095872  0.28146068\n",
      "  0.48453337  0.08721828  0.30963766  0.30938209  0.35643737  0.13123749\n",
      "  0.11089034  0.5906409   0.20029782  0.37904825  0.3114301   0.37348522\n",
      "  0.37439181  0.25397064 -0.00203283  0.33049452  0.29876734  0.29971454\n",
      "  0.32515046  0.19141426  0.13853618  0.1854582   0.24381902  0.18541554\n",
      "  0.36083728  0.18635625  0.3906087   0.25088267  0.13047574  0.17218653\n",
      "  0.25431538  0.39848962  0.28447481  0.1529979   0.45211025]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "number_predict = 100\n",
    "with torch.no_grad():\n",
    "    example_input = torch.tensor(X_test[:number_predict], dtype=torch.float32).to(\"mps\")\n",
    "    predictions = model(example_input).flatten().cpu().numpy()\n",
    "    # predictions = [int(round(pred)) for pred in predictions]\n",
    "\n",
    "print(\"Example Predictions:\", predictions)\n",
    "print(\"Ground Truth:\", y_test[:number_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271496</td>\n",
       "      <td>0.708417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.268247</td>\n",
       "      <td>0.253444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391407</td>\n",
       "      <td>0.169570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.303871</td>\n",
       "      <td>0.263607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214332</td>\n",
       "      <td>0.279264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred    y_test\n",
       "0  0.271496  0.708417\n",
       "1  0.268247  0.253444\n",
       "2  0.391407  0.169570\n",
       "3  0.303871  0.263607\n",
       "4  0.214332  0.279264"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\"y_pred\": predictions, \"y_test\": y_test[:number_predict]})\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.271496</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.616757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.268247</td>\n",
       "      <td>0.253444</td>\n",
       "      <td>0.058409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391407</td>\n",
       "      <td>0.169570</td>\n",
       "      <td>1.308231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.303871</td>\n",
       "      <td>0.263607</td>\n",
       "      <td>0.152743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214332</td>\n",
       "      <td>0.279264</td>\n",
       "      <td>0.232511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred    y_test      mape\n",
       "0  0.271496  0.708417  0.616757\n",
       "1  0.268247  0.253444  0.058409\n",
       "2  0.391407  0.169570  1.308231\n",
       "3  0.303871  0.263607  0.152743\n",
       "4  0.214332  0.279264  0.232511"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cal mape each row\n",
    "def cal_mape(row):\n",
    "    try:\n",
    "        return abs(row.y_pred - row.y_train) / row.y_train\n",
    "    except:\n",
    "        return abs(row.y_pred - row.y_test) / row.y_test\n",
    "\n",
    "\n",
    "result_df[\"mape\"] = result_df.apply(cal_mape, axis=1)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1702127659574468"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count mape < 0.15\n",
    "print(result_df[result_df.mape < 0.15].shape[0])\n",
    "result_df[result_df.mape < 0.15].shape[0] / result_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70841744, 0.25344402, 0.16957017, 0.26360735, 0.27926378])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2658486707566462"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_predict = 10000\n",
    "with torch.no_grad():\n",
    "    example_input = torch.tensor(X_val[:number_predict], dtype=torch.float32).to(\"mps\")\n",
    "    predictions = model(example_input).flatten().cpu().numpy()\n",
    "result_df = pd.DataFrame({\"y_pred\": predictions, \"y_train\": y_val[:number_predict]})\n",
    "result_df.head()\n",
    "\n",
    "result_df[\"mape\"] = result_df.apply(cal_mape, axis=1)\n",
    "result_df.head()\n",
    "print(result_df[result_df.mape < 0.15].shape[0])\n",
    "result_df[result_df.mape < 0.15].shape[0] / result_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_predict = 10000\n",
    "with torch.no_grad():\n",
    "    example_input = torch.tensor(X_train[:number_predict], dtype=torch.float32).to(\n",
    "        \"mps\"\n",
    "    )\n",
    "    predictions = model(example_input).flatten().cpu().numpy()\n",
    "    # predictions = [int(round(pred)) for pred in predictions]\n",
    "\n",
    "# print(\"Example Predictions:\", predictions)\n",
    "# print(\"Ground Truth:\", y_train[:number_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194830</td>\n",
       "      <td>0.165297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188511</td>\n",
       "      <td>0.247022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167674</td>\n",
       "      <td>0.092590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509392</td>\n",
       "      <td>0.642841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.228769</td>\n",
       "      <td>0.305953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred   y_train\n",
       "0  0.194830  0.165297\n",
       "1  0.188511  0.247022\n",
       "2  0.167674  0.092590\n",
       "3  0.509392  0.642841\n",
       "4  0.228769  0.305953"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\"y_pred\": predictions, \"y_train\": y_train[:number_predict]})\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_26440/724403404.py:4: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return abs(row.y_pred - row.y_train) / row.y_train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_train</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194830</td>\n",
       "      <td>0.165297</td>\n",
       "      <td>0.178669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188511</td>\n",
       "      <td>0.247022</td>\n",
       "      <td>0.236868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167674</td>\n",
       "      <td>0.092590</td>\n",
       "      <td>0.810939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509392</td>\n",
       "      <td>0.642841</td>\n",
       "      <td>0.207593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.228769</td>\n",
       "      <td>0.305953</td>\n",
       "      <td>0.252275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred   y_train      mape\n",
       "0  0.194830  0.165297  0.178669\n",
       "1  0.188511  0.247022  0.236868\n",
       "2  0.167674  0.092590  0.810939\n",
       "3  0.509392  0.642841  0.207593\n",
       "4  0.228769  0.305953  0.252275"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cal mape each row\n",
    "\n",
    "\n",
    "result_df[\"mape\"] = result_df.apply(cal_mape, axis=1)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3114754098360656"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result_df[result_df.mape < 0.15].shape[0])\n",
    "result_df[result_df.mape < 0.15].shape[0] / result_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
