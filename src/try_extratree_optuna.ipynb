{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>sum_pop_in_voronoi</th>\n",
       "      <th>voronoi_area</th>\n",
       "      <th>voronoi_density</th>\n",
       "      <th>cro_open_year</th>\n",
       "      <th>CRO_store_length</th>\n",
       "      <th>CRO_store_parking</th>\n",
       "      <th>CRO_store_stock_area</th>\n",
       "      <th>CRO_store_total_area</th>\n",
       "      <th>CRO_store_width</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_503</th>\n",
       "      <th>embedding_504</th>\n",
       "      <th>embedding_505</th>\n",
       "      <th>embedding_506</th>\n",
       "      <th>embedding_507</th>\n",
       "      <th>embedding_508</th>\n",
       "      <th>embedding_509</th>\n",
       "      <th>embedding_510</th>\n",
       "      <th>embedding_511</th>\n",
       "      <th>embedding_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1025.0</td>\n",
       "      <td>16369.32</td>\n",
       "      <td>38412.2</td>\n",
       "      <td>0.426149</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.39</td>\n",
       "      <td>274.39</td>\n",
       "      <td>14.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618719</td>\n",
       "      <td>0.397206</td>\n",
       "      <td>0.539024</td>\n",
       "      <td>0.034935</td>\n",
       "      <td>-0.425025</td>\n",
       "      <td>-0.202426</td>\n",
       "      <td>-0.603762</td>\n",
       "      <td>-0.113011</td>\n",
       "      <td>0.282425</td>\n",
       "      <td>-0.264580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8396.0</td>\n",
       "      <td>15736.69</td>\n",
       "      <td>241705.5</td>\n",
       "      <td>0.065107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.86</td>\n",
       "      <td>175.86</td>\n",
       "      <td>19.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853443</td>\n",
       "      <td>0.604886</td>\n",
       "      <td>0.487524</td>\n",
       "      <td>0.250037</td>\n",
       "      <td>-0.343431</td>\n",
       "      <td>0.215231</td>\n",
       "      <td>-0.492256</td>\n",
       "      <td>-0.528084</td>\n",
       "      <td>-0.124986</td>\n",
       "      <td>-0.288903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8572.0</td>\n",
       "      <td>16156.14</td>\n",
       "      <td>193980.1</td>\n",
       "      <td>0.083288</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.90</td>\n",
       "      <td>145.90</td>\n",
       "      <td>17.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461060</td>\n",
       "      <td>0.396897</td>\n",
       "      <td>0.465704</td>\n",
       "      <td>0.372753</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.028150</td>\n",
       "      <td>-0.261129</td>\n",
       "      <td>-0.084676</td>\n",
       "      <td>-0.178961</td>\n",
       "      <td>0.154477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1058.0</td>\n",
       "      <td>11213.96</td>\n",
       "      <td>77343.2</td>\n",
       "      <td>0.144990</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.83</td>\n",
       "      <td>93.83</td>\n",
       "      <td>7.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755208</td>\n",
       "      <td>0.682671</td>\n",
       "      <td>0.673349</td>\n",
       "      <td>-0.079623</td>\n",
       "      <td>-0.562957</td>\n",
       "      <td>-0.830060</td>\n",
       "      <td>-0.801435</td>\n",
       "      <td>-0.366279</td>\n",
       "      <td>0.880094</td>\n",
       "      <td>0.253283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>16216.47</td>\n",
       "      <td>90980.3</td>\n",
       "      <td>0.178242</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.18</td>\n",
       "      <td>113.18</td>\n",
       "      <td>7.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432766</td>\n",
       "      <td>0.767998</td>\n",
       "      <td>0.388810</td>\n",
       "      <td>0.492982</td>\n",
       "      <td>0.151838</td>\n",
       "      <td>-0.086584</td>\n",
       "      <td>-0.651078</td>\n",
       "      <td>-0.546258</td>\n",
       "      <td>-0.215056</td>\n",
       "      <td>-0.015719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 897 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id  sum_pop_in_voronoi  voronoi_area  voronoi_density  cro_open_year  \\\n",
       "0    1025.0            16369.32       38412.2         0.426149           16.0   \n",
       "1    8396.0            15736.69      241705.5         0.065107           16.0   \n",
       "2    8572.0            16156.14      193980.1         0.083288           16.0   \n",
       "3    1058.0            11213.96       77343.2         0.144990           16.0   \n",
       "4    1095.0            16216.47       90980.3         0.178242           16.0   \n",
       "\n",
       "   CRO_store_length  CRO_store_parking  CRO_store_stock_area  \\\n",
       "0             20.00                0.0                 97.39   \n",
       "1             15.35                0.0                 44.86   \n",
       "2              9.85                0.0                 12.90   \n",
       "3             13.94                0.0                 11.83   \n",
       "4             15.82                0.0                 35.18   \n",
       "\n",
       "   CRO_store_total_area  CRO_store_width  ...  embedding_503  embedding_504  \\\n",
       "0                274.39            14.00  ...       0.618719       0.397206   \n",
       "1                175.86            19.80  ...       0.853443       0.604886   \n",
       "2                145.90            17.80  ...       0.461060       0.396897   \n",
       "3                 93.83             7.90  ...       0.755208       0.682671   \n",
       "4                113.18             7.94  ...       0.432766       0.767998   \n",
       "\n",
       "   embedding_505  embedding_506  embedding_507  embedding_508  embedding_509  \\\n",
       "0       0.539024       0.034935      -0.425025      -0.202426      -0.603762   \n",
       "1       0.487524       0.250037      -0.343431       0.215231      -0.492256   \n",
       "2       0.465704       0.372753       0.014367       0.028150      -0.261129   \n",
       "3       0.673349      -0.079623      -0.562957      -0.830060      -0.801435   \n",
       "4       0.388810       0.492982       0.151838      -0.086584      -0.651078   \n",
       "\n",
       "   embedding_510  embedding_511  embedding_512  \n",
       "0      -0.113011       0.282425      -0.264580  \n",
       "1      -0.528084      -0.124986      -0.288903  \n",
       "2      -0.084676      -0.178961       0.154477  \n",
       "3      -0.366279       0.880094       0.253283  \n",
       "4      -0.546258      -0.215056      -0.015719  \n",
       "\n",
       "[5 rows x 897 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_path = \"data/train.csv\"\n",
    "# test_df_path = \"data/test.csv\"\n",
    "# train_df = pd.read_csv(train_df_path)\n",
    "# test_df = pd.read_csv(test_df_path)\n",
    "new_df_path = \"/Users/user/Documents/Coding/cro_location_intelligence/src/data/all_data_embedding.csv\"\n",
    "df = pd.read_csv(new_df_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use embedding to predict mockup_sale with xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# get all column has embedding_ prefix\n",
    "# feature_columns = [col for col in df.columns if col.startswith(\"embedding_\")]\n",
    "# feature_columns += [\"subset\"]\n",
    "# feature_columns += [\"y_nor\"]\n",
    "# assign to x\n",
    "# all_data = df[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>886</th>\n",
       "      <th>887</th>\n",
       "      <th>888</th>\n",
       "      <th>889</th>\n",
       "      <th>890</th>\n",
       "      <th>891</th>\n",
       "      <th>892</th>\n",
       "      <th>893</th>\n",
       "      <th>y_nor</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809053</td>\n",
       "      <td>-0.435626</td>\n",
       "      <td>1.276019</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>1.119992</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>1.958702</td>\n",
       "      <td>1.316572</td>\n",
       "      <td>-0.099400</td>\n",
       "      <td>1.694327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457054</td>\n",
       "      <td>-0.610891</td>\n",
       "      <td>-0.983325</td>\n",
       "      <td>-0.104843</td>\n",
       "      <td>-0.690702</td>\n",
       "      <td>0.676902</td>\n",
       "      <td>-0.050310</td>\n",
       "      <td>-0.970355</td>\n",
       "      <td>0.226238</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.587070</td>\n",
       "      <td>-0.246327</td>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-0.168104</td>\n",
       "      <td>-0.166140</td>\n",
       "      <td>0.836214</td>\n",
       "      <td>1.078724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214278</td>\n",
       "      <td>0.107851</td>\n",
       "      <td>-0.604111</td>\n",
       "      <td>1.191268</td>\n",
       "      <td>-0.142626</td>\n",
       "      <td>-0.891032</td>\n",
       "      <td>-1.833997</td>\n",
       "      <td>-1.052687</td>\n",
       "      <td>0.182798</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734251</td>\n",
       "      <td>-0.290767</td>\n",
       "      <td>-0.193664</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>-1.067295</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-1.462083</td>\n",
       "      <td>-0.616988</td>\n",
       "      <td>0.513588</td>\n",
       "      <td>-0.768087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111415</td>\n",
       "      <td>0.517898</td>\n",
       "      <td>1.058781</td>\n",
       "      <td>0.610704</td>\n",
       "      <td>0.993412</td>\n",
       "      <td>0.783935</td>\n",
       "      <td>-2.070301</td>\n",
       "      <td>0.448145</td>\n",
       "      <td>0.433002</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.999912</td>\n",
       "      <td>-0.399375</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>-0.185915</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-1.505405</td>\n",
       "      <td>-1.400555</td>\n",
       "      <td>-1.083407</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090279</td>\n",
       "      <td>-0.993677</td>\n",
       "      <td>-1.624377</td>\n",
       "      <td>-2.052572</td>\n",
       "      <td>-1.662305</td>\n",
       "      <td>-0.279813</td>\n",
       "      <td>2.566342</td>\n",
       "      <td>0.782599</td>\n",
       "      <td>0.221966</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755420</td>\n",
       "      <td>-0.386677</td>\n",
       "      <td>0.213359</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-0.560023</td>\n",
       "      <td>-1.109370</td>\n",
       "      <td>-1.076954</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251072</td>\n",
       "      <td>0.919632</td>\n",
       "      <td>1.697689</td>\n",
       "      <td>0.254650</td>\n",
       "      <td>-0.923269</td>\n",
       "      <td>-0.959682</td>\n",
       "      <td>-2.228328</td>\n",
       "      <td>-0.127967</td>\n",
       "      <td>0.149573</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 896 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4        5         6  \\\n",
       "0  0.809053 -0.435626  1.276019 -0.585552  1.119992 -0.60246  1.958702   \n",
       "1  0.587070 -0.246327 -0.271598 -0.585552  0.117934 -0.60246 -0.168104   \n",
       "2  0.734251 -0.290767 -0.193664 -0.585552 -1.067295 -0.60246 -1.462083   \n",
       "3 -0.999912 -0.399375  0.070823 -0.585552 -0.185915 -0.60246 -1.505405   \n",
       "4  0.755420 -0.386677  0.213359 -0.585552  0.219217 -0.60246 -0.560023   \n",
       "\n",
       "          7         8         9  ...       886       887       888       889  \\\n",
       "0  1.316572 -0.099400  1.694327  ...  0.457054 -0.610891 -0.983325 -0.104843   \n",
       "1 -0.166140  0.836214  1.078724  ...  0.214278  0.107851 -0.604111  1.191268   \n",
       "2 -0.616988  0.513588 -0.768087  ...  0.111415  0.517898  1.058781  0.610704   \n",
       "3 -1.400555 -1.083407  0.463120  ...  1.090279 -0.993677 -1.624377 -2.052572   \n",
       "4 -1.109370 -1.076954  0.463120  ... -0.251072  0.919632  1.697689  0.254650   \n",
       "\n",
       "        890       891       892       893     y_nor  subset  \n",
       "0 -0.690702  0.676902 -0.050310 -0.970355  0.226238   train  \n",
       "1 -0.142626 -0.891032 -1.833997 -1.052687  0.182798   train  \n",
       "2  0.993412  0.783935 -2.070301  0.448145  0.433002   train  \n",
       "3 -1.662305 -0.279813  2.566342  0.782599  0.221966   train  \n",
       "4 -0.923269 -0.959682 -2.228328 -0.127967  0.149573   train  \n",
       "\n",
       "[5 rows x 896 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize every column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "all_data = df.copy()\n",
    "all_data = all_data.drop(columns=[\"store_id\"])\n",
    "all_data = all_data.drop(columns=[\"y_nor\"])\n",
    "train_all_data = all_data[all_data.subset == \"train\"]\n",
    "all_data = all_data.drop(columns=[\"subset\"])\n",
    "train_all_data = train_all_data.drop(columns=[\"subset\"])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_all_data)\n",
    "all_data = scaler.transform(all_data)\n",
    "all_data = pd.DataFrame(all_data)\n",
    "# all_data.columns = feature_columns\n",
    "# all_data[\"store_id\"] = df[\"store_id\"]\n",
    "all_data[\"y_nor\"] = df[\"y_nor\"]\n",
    "all_data[\"subset\"] = df[\"subset\"]\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create noise data\n",
    "def create_noise_data(data, times_sample, noise_level=0.1):\n",
    "    new_data = data.copy()\n",
    "    assert times_sample > 0 and isinstance(times_sample, int)\n",
    "    for _ in range(times_sample):\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "\n",
    "        noise_data = data + noise\n",
    "        new_data = pd.concat([new_data, noise_data])\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488, 894)\n",
      "(489, 894)\n",
      "(10248, 894)\n",
      "(489, 894)\n"
     ]
    }
   ],
   "source": [
    "X = all_data[all_data.subset == \"train\"]\n",
    "X = X.drop(columns=[\"subset\"])\n",
    "y = X[\"y_nor\"]\n",
    "X_test = all_data[all_data.subset == \"test\"]\n",
    "X_test = X_test.drop(columns=[\"subset\"])\n",
    "y_test = X_test[\"y_nor\"]\n",
    "X = X.drop(columns=[\"y_nor\"])\n",
    "X_test = X_test.drop(columns=[\"y_nor\"])\n",
    "\n",
    "\n",
    "# Assuming you have X, X_valid, y, y_valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "train_noise = 0.25\n",
    "valid_noise = 0.1\n",
    "X_train = create_noise_data(X_train, 20, noise_level=train_noise)\n",
    "# X_valid = create_noise_data(X_valid, 10, noise_level=train_noise / 10)\n",
    "y_train = create_noise_data(y_train, 20, noise_level=valid_noise)\n",
    "# y_valid = create_noise_data(y_valid, 10, noise_level=valid_noise / 10)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-21 09:24:22,800] A new study created in memory with name: no-name-ecb85439-2731-46cb-b461-777e4352d636\n",
      "[I 2023-12-21 09:27:19,875] Trial 0 finished with value: -0.008386096916071228 and parameters: {'n_estimators': 791, 'max_depth': 37, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': 0.3053451340149207}. Best is trial 0 with value: -0.008386096916071228.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Assuming train_df and test_df are your training and testing DataFrames\n",
    "\n",
    "# Separate features (X) and target variable (y) in the training set\n",
    "# X_train = train_df.drop([\"y_nor\", \"store_id\"], axis=1)\n",
    "# y_train = train_df[\"y_nor\"]\n",
    "\n",
    "# Separate features (X) and target variable (y) in the test set\n",
    "# X_test = test_df.drop([\"y_nor\", \"store_id\"], axis=1)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1000),\n",
    "        # \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 5000),\n",
    "        # \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 20, 40),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 50),\n",
    "        \"max_features\": trial.suggest_float(\"max_features\", 0.1, 1.0),\n",
    "    }\n",
    "\n",
    "    model = ExtraTreesRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    # rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    val_df = pd.DataFrame()\n",
    "    val_df[\"y_nor\"] = y_valid\n",
    "    val_df[\"predicted_y_nor\"] = y_pred\n",
    "    val_df[\"mape\"] = abs(val_df[\"y_nor\"] - val_df[\"predicted_y_nor\"]) / val_df[\"y_nor\"]\n",
    "    val_correct = val_df[val_df[\"mape\"] < 0.15].shape[0]\n",
    "    avg_mape = val_df[\"mape\"].mean()\n",
    "    loss = -avg_mape + (val_correct / val_df.shape[0])\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Create a study object and optimize the objective function using Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score -0.008386096916071228\n",
      "Best Hyperparameters: {'n_estimators': 791, 'max_depth': 37, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': 0.3053451340149207}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 791,\n",
       " 'max_depth': 37,\n",
       " 'min_samples_split': 8,\n",
       " 'min_samples_leaf': 12,\n",
       " 'max_features': 0.3053451340149207}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"score\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "display(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Get the best hyperparameters from the study\n",
    "\n",
    "# Create the final model using the best hyperparameters\n",
    "final_model = ExtraTreesRegressor(**best_params, random_state=42)\n",
    "# final_model = ExtraTreesRegressor()\n",
    "# final_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "# final_model = xgb.XGBRegressor()\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "final_model.fit(X, y)\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = final_model.predict(X_test)\n",
    "y_pred_train = final_model.predict(X)\n",
    "y_pred_valid = final_model.predict(X_valid)\n",
    "test_df = X_test.copy()\n",
    "test_df[\"y_nor\"] = y_test\n",
    "train_df = X.copy()\n",
    "train_df[\"y_nor\"] = y\n",
    "val_df = X_valid.copy()\n",
    "val_df[\"y_nor\"] = y_valid\n",
    "\n",
    "# Add the predictions to the test_df DataFrame\n",
    "test_df[\"predicted_y_nor\"] = y_pred_test\n",
    "\n",
    "train_df[\"predicted_y_nor\"] = y_pred_train\n",
    "val_df[\"predicted_y_nor\"] = y_pred_valid\n",
    "# Map store_id back to the test_df DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_correct 17\n",
      "accuracy 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Assuming you have the actual target values for the test set in y_test\n",
    "y_test = test_df[\"y_nor\"]\n",
    "\n",
    "# Extract predicted values from the DataFrame\n",
    "predictions = test_df[\"predicted_y_nor\"]\n",
    "test_df[\"mape\"] = abs(test_df[\"y_nor\"] - test_df[\"predicted_y_nor\"]) / test_df[\"y_nor\"]\n",
    "\n",
    "\n",
    "selected_columns = [\"y_nor\", \"predicted_y_nor\", \"mape\"]\n",
    "test_df[selected_columns].head()\n",
    "# count mape<0.15\n",
    "test_correct = test_df[test_df[\"mape\"] < 0.15].shape[0]\n",
    "test_df.shape[0]\n",
    "print(\"test_correct\", test_correct)\n",
    "print(f\"accuracy {test_correct / test_df.shape[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_correct 225\n",
      "accuracy 0.46\n"
     ]
    }
   ],
   "source": [
    "# val\n",
    "val_df[\"mape\"] = abs(val_df[\"y_nor\"] - val_df[\"predicted_y_nor\"]) / val_df[\"y_nor\"]\n",
    "val_correct = val_df[val_df[\"mape\"] < 0.15].shape[0]\n",
    "val_df.shape[0]\n",
    "print(\"val_correct\", val_correct)\n",
    "print(f\"accuracy {val_correct / val_df.shape[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_correct 448\n",
      "accuracy 0.46\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train_df[\"mape\"] = (\n",
    "    abs(train_df[\"y_nor\"] - train_df[\"predicted_y_nor\"]) / train_df[\"y_nor\"]\n",
    ")\n",
    "train_correct = train_df[train_df[\"mape\"] < 0.15].shape[0]\n",
    "train_df.shape[0]\n",
    "print(\"train_correct\", train_correct)\n",
    "print(f\"accuracy {train_correct / train_df.shape[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "for i in range(10):\n",
    "    print(int(i + 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(1.5), int(2.5), int(3.5), int(4.5), int(5.5), int(6.5), int(7.5), int(8.5), int(\n",
    "    9.5\n",
    "), int(10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor(1.5), math.floor(2.5), math.floor(3.5), math.floor(4.5), math.floor(\n",
    "    5.5\n",
    "), math.floor(6.5), math.floor(7.5), math.floor(8.5), math.floor(9.5), math.floor(10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5, 6, 7, 8, 9, 10, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(1.5), math.ceil(2.5), math.ceil(3.5), math.ceil(4.5), math.ceil(\n",
    "    5.5\n",
    "), math.ceil(6.5), math.ceil(7.5), math.ceil(8.5), math.ceil(9.5), math.ceil(10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 4, 4, 6, 6, 8, 8, 10, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.5), round(2.5), round(3.5), round(4.5), round(5.5), round(6.5), round(\n",
    "    7.5\n",
    "), round(8.5), round(9.5), round(10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
