{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>sum_pop_in_voronoi</th>\n",
       "      <th>voronoi_area</th>\n",
       "      <th>voronoi_density</th>\n",
       "      <th>cro_open_year</th>\n",
       "      <th>CRO_store_length</th>\n",
       "      <th>CRO_store_parking</th>\n",
       "      <th>CRO_store_stock_area</th>\n",
       "      <th>CRO_store_total_area</th>\n",
       "      <th>CRO_store_width</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_503</th>\n",
       "      <th>embedding_504</th>\n",
       "      <th>embedding_505</th>\n",
       "      <th>embedding_506</th>\n",
       "      <th>embedding_507</th>\n",
       "      <th>embedding_508</th>\n",
       "      <th>embedding_509</th>\n",
       "      <th>embedding_510</th>\n",
       "      <th>embedding_511</th>\n",
       "      <th>embedding_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1025.0</td>\n",
       "      <td>16369.32</td>\n",
       "      <td>38412.2</td>\n",
       "      <td>0.426149</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.39</td>\n",
       "      <td>274.39</td>\n",
       "      <td>14.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618719</td>\n",
       "      <td>0.397206</td>\n",
       "      <td>0.539024</td>\n",
       "      <td>0.034935</td>\n",
       "      <td>-0.425025</td>\n",
       "      <td>-0.202426</td>\n",
       "      <td>-0.603762</td>\n",
       "      <td>-0.113011</td>\n",
       "      <td>0.282425</td>\n",
       "      <td>-0.264580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8396.0</td>\n",
       "      <td>15736.69</td>\n",
       "      <td>241705.5</td>\n",
       "      <td>0.065107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.86</td>\n",
       "      <td>175.86</td>\n",
       "      <td>19.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853443</td>\n",
       "      <td>0.604886</td>\n",
       "      <td>0.487524</td>\n",
       "      <td>0.250037</td>\n",
       "      <td>-0.343431</td>\n",
       "      <td>0.215231</td>\n",
       "      <td>-0.492256</td>\n",
       "      <td>-0.528084</td>\n",
       "      <td>-0.124986</td>\n",
       "      <td>-0.288903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8572.0</td>\n",
       "      <td>16156.14</td>\n",
       "      <td>193980.1</td>\n",
       "      <td>0.083288</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.90</td>\n",
       "      <td>145.90</td>\n",
       "      <td>17.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461060</td>\n",
       "      <td>0.396897</td>\n",
       "      <td>0.465704</td>\n",
       "      <td>0.372753</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.028150</td>\n",
       "      <td>-0.261129</td>\n",
       "      <td>-0.084676</td>\n",
       "      <td>-0.178961</td>\n",
       "      <td>0.154477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1058.0</td>\n",
       "      <td>11213.96</td>\n",
       "      <td>77343.2</td>\n",
       "      <td>0.144990</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.83</td>\n",
       "      <td>93.83</td>\n",
       "      <td>7.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755208</td>\n",
       "      <td>0.682671</td>\n",
       "      <td>0.673349</td>\n",
       "      <td>-0.079623</td>\n",
       "      <td>-0.562957</td>\n",
       "      <td>-0.830060</td>\n",
       "      <td>-0.801435</td>\n",
       "      <td>-0.366279</td>\n",
       "      <td>0.880094</td>\n",
       "      <td>0.253283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>16216.47</td>\n",
       "      <td>90980.3</td>\n",
       "      <td>0.178242</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.18</td>\n",
       "      <td>113.18</td>\n",
       "      <td>7.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432766</td>\n",
       "      <td>0.767998</td>\n",
       "      <td>0.388810</td>\n",
       "      <td>0.492982</td>\n",
       "      <td>0.151838</td>\n",
       "      <td>-0.086584</td>\n",
       "      <td>-0.651078</td>\n",
       "      <td>-0.546258</td>\n",
       "      <td>-0.215056</td>\n",
       "      <td>-0.015719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 897 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id  sum_pop_in_voronoi  voronoi_area  voronoi_density  cro_open_year  \\\n",
       "0    1025.0            16369.32       38412.2         0.426149           16.0   \n",
       "1    8396.0            15736.69      241705.5         0.065107           16.0   \n",
       "2    8572.0            16156.14      193980.1         0.083288           16.0   \n",
       "3    1058.0            11213.96       77343.2         0.144990           16.0   \n",
       "4    1095.0            16216.47       90980.3         0.178242           16.0   \n",
       "\n",
       "   CRO_store_length  CRO_store_parking  CRO_store_stock_area  \\\n",
       "0             20.00                0.0                 97.39   \n",
       "1             15.35                0.0                 44.86   \n",
       "2              9.85                0.0                 12.90   \n",
       "3             13.94                0.0                 11.83   \n",
       "4             15.82                0.0                 35.18   \n",
       "\n",
       "   CRO_store_total_area  CRO_store_width  ...  embedding_503  embedding_504  \\\n",
       "0                274.39            14.00  ...       0.618719       0.397206   \n",
       "1                175.86            19.80  ...       0.853443       0.604886   \n",
       "2                145.90            17.80  ...       0.461060       0.396897   \n",
       "3                 93.83             7.90  ...       0.755208       0.682671   \n",
       "4                113.18             7.94  ...       0.432766       0.767998   \n",
       "\n",
       "   embedding_505  embedding_506  embedding_507  embedding_508  embedding_509  \\\n",
       "0       0.539024       0.034935      -0.425025      -0.202426      -0.603762   \n",
       "1       0.487524       0.250037      -0.343431       0.215231      -0.492256   \n",
       "2       0.465704       0.372753       0.014367       0.028150      -0.261129   \n",
       "3       0.673349      -0.079623      -0.562957      -0.830060      -0.801435   \n",
       "4       0.388810       0.492982       0.151838      -0.086584      -0.651078   \n",
       "\n",
       "   embedding_510  embedding_511  embedding_512  \n",
       "0      -0.113011       0.282425      -0.264580  \n",
       "1      -0.528084      -0.124986      -0.288903  \n",
       "2      -0.084676      -0.178961       0.154477  \n",
       "3      -0.366279       0.880094       0.253283  \n",
       "4      -0.546258      -0.215056      -0.015719  \n",
       "\n",
       "[5 rows x 897 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_path = \"data/train.csv\"\n",
    "# test_df_path = \"data/test.csv\"\n",
    "# train_df = pd.read_csv(train_df_path)\n",
    "# test_df = pd.read_csv(test_df_path)\n",
    "new_df_path = \"/Users/user/Documents/Coding/cro_location_intelligence/src/data/all_data_embedding.csv\"\n",
    "df = pd.read_csv(new_df_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use embedding to predict mockup_sale with xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# get all column has embedding_ prefix\n",
    "# feature_columns = [col for col in df.columns if col.startswith(\"embedding_\")]\n",
    "# feature_columns += [\"subset\"]\n",
    "# feature_columns += [\"y_nor\"]\n",
    "# assign to x\n",
    "# all_data = df[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>886</th>\n",
       "      <th>887</th>\n",
       "      <th>888</th>\n",
       "      <th>889</th>\n",
       "      <th>890</th>\n",
       "      <th>891</th>\n",
       "      <th>892</th>\n",
       "      <th>893</th>\n",
       "      <th>y_nor</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.809053</td>\n",
       "      <td>-0.435626</td>\n",
       "      <td>1.276019</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>1.119992</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>1.958702</td>\n",
       "      <td>1.316572</td>\n",
       "      <td>-0.099400</td>\n",
       "      <td>1.694327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457054</td>\n",
       "      <td>-0.610891</td>\n",
       "      <td>-0.983325</td>\n",
       "      <td>-0.104843</td>\n",
       "      <td>-0.690702</td>\n",
       "      <td>0.676902</td>\n",
       "      <td>-0.050310</td>\n",
       "      <td>-0.970355</td>\n",
       "      <td>0.226238</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.587070</td>\n",
       "      <td>-0.246327</td>\n",
       "      <td>-0.271598</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-0.168104</td>\n",
       "      <td>-0.166140</td>\n",
       "      <td>0.836214</td>\n",
       "      <td>1.078724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214278</td>\n",
       "      <td>0.107851</td>\n",
       "      <td>-0.604111</td>\n",
       "      <td>1.191268</td>\n",
       "      <td>-0.142626</td>\n",
       "      <td>-0.891032</td>\n",
       "      <td>-1.833997</td>\n",
       "      <td>-1.052687</td>\n",
       "      <td>0.182798</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734251</td>\n",
       "      <td>-0.290767</td>\n",
       "      <td>-0.193664</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>-1.067295</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-1.462083</td>\n",
       "      <td>-0.616988</td>\n",
       "      <td>0.513588</td>\n",
       "      <td>-0.768087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111415</td>\n",
       "      <td>0.517898</td>\n",
       "      <td>1.058781</td>\n",
       "      <td>0.610704</td>\n",
       "      <td>0.993412</td>\n",
       "      <td>0.783935</td>\n",
       "      <td>-2.070301</td>\n",
       "      <td>0.448145</td>\n",
       "      <td>0.433002</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.999912</td>\n",
       "      <td>-0.399375</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>-0.185915</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-1.505405</td>\n",
       "      <td>-1.400555</td>\n",
       "      <td>-1.083407</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090279</td>\n",
       "      <td>-0.993677</td>\n",
       "      <td>-1.624377</td>\n",
       "      <td>-2.052572</td>\n",
       "      <td>-1.662305</td>\n",
       "      <td>-0.279813</td>\n",
       "      <td>2.566342</td>\n",
       "      <td>0.782599</td>\n",
       "      <td>0.221966</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755420</td>\n",
       "      <td>-0.386677</td>\n",
       "      <td>0.213359</td>\n",
       "      <td>-0.585552</td>\n",
       "      <td>0.219217</td>\n",
       "      <td>-0.60246</td>\n",
       "      <td>-0.560023</td>\n",
       "      <td>-1.109370</td>\n",
       "      <td>-1.076954</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251072</td>\n",
       "      <td>0.919632</td>\n",
       "      <td>1.697689</td>\n",
       "      <td>0.254650</td>\n",
       "      <td>-0.923269</td>\n",
       "      <td>-0.959682</td>\n",
       "      <td>-2.228328</td>\n",
       "      <td>-0.127967</td>\n",
       "      <td>0.149573</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 896 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4        5         6  \\\n",
       "0  0.809053 -0.435626  1.276019 -0.585552  1.119992 -0.60246  1.958702   \n",
       "1  0.587070 -0.246327 -0.271598 -0.585552  0.117934 -0.60246 -0.168104   \n",
       "2  0.734251 -0.290767 -0.193664 -0.585552 -1.067295 -0.60246 -1.462083   \n",
       "3 -0.999912 -0.399375  0.070823 -0.585552 -0.185915 -0.60246 -1.505405   \n",
       "4  0.755420 -0.386677  0.213359 -0.585552  0.219217 -0.60246 -0.560023   \n",
       "\n",
       "          7         8         9  ...       886       887       888       889  \\\n",
       "0  1.316572 -0.099400  1.694327  ...  0.457054 -0.610891 -0.983325 -0.104843   \n",
       "1 -0.166140  0.836214  1.078724  ...  0.214278  0.107851 -0.604111  1.191268   \n",
       "2 -0.616988  0.513588 -0.768087  ...  0.111415  0.517898  1.058781  0.610704   \n",
       "3 -1.400555 -1.083407  0.463120  ...  1.090279 -0.993677 -1.624377 -2.052572   \n",
       "4 -1.109370 -1.076954  0.463120  ... -0.251072  0.919632  1.697689  0.254650   \n",
       "\n",
       "        890       891       892       893     y_nor  subset  \n",
       "0 -0.690702  0.676902 -0.050310 -0.970355  0.226238   train  \n",
       "1 -0.142626 -0.891032 -1.833997 -1.052687  0.182798   train  \n",
       "2  0.993412  0.783935 -2.070301  0.448145  0.433002   train  \n",
       "3 -1.662305 -0.279813  2.566342  0.782599  0.221966   train  \n",
       "4 -0.923269 -0.959682 -2.228328 -0.127967  0.149573   train  \n",
       "\n",
       "[5 rows x 896 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize every column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "all_data = df.copy()\n",
    "all_data = all_data.drop(columns=[\"store_id\"])\n",
    "all_data = all_data.drop(columns=[\"y_nor\"])\n",
    "train_all_data = all_data[all_data.subset == \"train\"]\n",
    "all_data = all_data.drop(columns=[\"subset\"])\n",
    "train_all_data = train_all_data.drop(columns=[\"subset\"])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_all_data)\n",
    "all_data = scaler.transform(all_data)\n",
    "all_data = pd.DataFrame(all_data)\n",
    "# all_data.columns = feature_columns\n",
    "# all_data[\"store_id\"] = df[\"store_id\"]\n",
    "all_data[\"y_nor\"] = df[\"y_nor\"]\n",
    "all_data[\"subset\"] = df[\"subset\"]\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create noise data\n",
    "def create_noise_data(data, times_sample, noise_level=0.1):\n",
    "    new_data = data.copy()\n",
    "    assert times_sample > 0 and isinstance(times_sample, int)\n",
    "    for _ in range(times_sample):\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "\n",
    "        noise_data = data + noise\n",
    "        new_data = pd.concat([new_data, noise_data])\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586, 894)\n",
      "(391, 894)\n",
      "(6446, 894)\n",
      "(391, 894)\n"
     ]
    }
   ],
   "source": [
    "X = all_data[all_data.subset == \"train\"]\n",
    "X = X.drop(columns=[\"subset\"])\n",
    "y = X[\"y_nor\"]\n",
    "X_test = all_data[all_data.subset == \"test\"]\n",
    "X_test = X_test.drop(columns=[\"subset\"])\n",
    "y_test = X_test[\"y_nor\"]\n",
    "X = X.drop(columns=[\"y_nor\"])\n",
    "X_test = X_test.drop(columns=[\"y_nor\"])\n",
    "\n",
    "\n",
    "# Assuming you have X, X_valid, y, y_valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "X_train = create_noise_data(X_train, 10, noise_level=0.25)\n",
    "# X_valid = create_noise_data(X_valid, 10, noise_level=0.25)\n",
    "y_train = create_noise_data(y_train, 10, noise_level=0.1)\n",
    "# y_valid = create_noise_data(y_valid, 10, noise_level=0.1)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-14 14:13:48,439] A new study created in memory with name: no-name-f052ec3c-2ea9-4675-b360-e3e95a21c034\n",
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_62948/1599092795.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_62948/1599092795.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_62948/1599092795.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"eta\": trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_62948/1599092795.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_62948/1599092795.py:28: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.1, 1.0),\n",
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_62948/1599092795.py:29: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 1.0),\n",
      "/var/folders/9g/3rr3k99j0td2974k71sy46_h0000gp/T/ipykernel_62948/1599092795.py:32: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-4, 1.0),\n",
      "/Users/user/miniconda3/lib/python3.11/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2023-12-14 14:13:55,633] Trial 3 finished with value: 0.08989768494458099 and parameters: {'lambda': 0.8226516227759868, 'alpha': 1.4135427462827407e-05, 'max_depth': 6, 'eta': 6.5886252538597155e-06, 'gamma': 0.00020302042169817732, 'subsample': 0.510358433878495, 'colsample_bytree': 0.36795046116791585, 'min_child_weight': 7, 'n_estimators': 208, 'learning_rate': 0.102853525134955}. Best is trial 3 with value: 0.08989768494458099.\n",
      "[I 2023-12-14 14:14:11,735] Trial 2 finished with value: 0.09870399956448994 and parameters: {'lambda': 0.00010213183493169869, 'alpha': 7.746015916188454e-05, 'max_depth': 18, 'eta': 3.549691510549174e-05, 'gamma': 2.8349486637957804e-05, 'subsample': 0.8626167819243958, 'colsample_bytree': 0.6800818701006175, 'min_child_weight': 4, 'n_estimators': 511, 'learning_rate': 0.23048008697923583}. Best is trial 3 with value: 0.08989768494458099.\n",
      "[I 2023-12-14 14:16:30,220] Trial 1 finished with value: 0.10737068898780261 and parameters: {'lambda': 3.1674428470874155e-06, 'alpha': 0.0022430886088515498, 'max_depth': 20, 'eta': 2.049460111569867e-07, 'gamma': 0.0006986426125966726, 'subsample': 0.4068946387177289, 'colsample_bytree': 0.21170996053317553, 'min_child_weight': 1, 'n_estimators': 178, 'learning_rate': 0.0023459773441452184}. Best is trial 3 with value: 0.08989768494458099.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/user/Documents/Coding/cro_location_intelligence/src/try_xgboost_optuna.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/user/Documents/Coding/cro_location_intelligence/src/try_xgboost_optuna.ipynb#X26sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Create a study object and optimize the objective function using Optuna\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/user/Documents/Coding/cro_location_intelligence/src/try_xgboost_optuna.ipynb#X26sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/user/Documents/Coding/cro_location_intelligence/src/try_xgboost_optuna.ipynb#X26sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:85\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     82\u001b[0m time_start \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m     83\u001b[0m futures: Set[Future] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m---> 85\u001b[0m \u001b[39mwith\u001b[39;49;00m ThreadPoolExecutor(max_workers\u001b[39m=\u001b[39;49mn_jobs) \u001b[39mas\u001b[39;49;00m executor:\n\u001b[1;32m     86\u001b[0m     \u001b[39mfor\u001b[39;49;00m n_submitted_trials \u001b[39min\u001b[39;49;00m itertools\u001b[39m.\u001b[39;49mcount():\n\u001b[1;32m     87\u001b[0m         \u001b[39mif\u001b[39;49;00m study\u001b[39m.\u001b[39;49m_stop_flag:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Assuming train_df and test_df are your training and testing DataFrames\n",
    "\n",
    "# Separate features (X) and target variable (y) in the training set\n",
    "# X_train = train_df.drop([\"y_nor\", \"store_id\"], axis=1)\n",
    "# y_train = train_df[\"y_nor\"]\n",
    "\n",
    "# # Separate features (X) and target variable (y) in the test set\n",
    "# X_test = test_df.drop([\"y_nor\", \"store_id\"], axis=1)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"eta\": trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
    "        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.1, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-4, 1.0),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**params, random_state=42)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "    y_pred = model.predict(X_valid)\n",
    "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Create a study object and optimize the objective function using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08989768494458099"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'lambda': 0.8226516227759868, 'alpha': 1.4135427462827407e-05, 'max_depth': 6, 'eta': 6.5886252538597155e-06, 'gamma': 0.00020302042169817732, 'subsample': 0.510358433878495, 'colsample_bytree': 0.36795046116791585, 'min_child_weight': 7, 'n_estimators': 208, 'learning_rate': 0.102853525134955}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lambda': 0.8226516227759868,\n",
       " 'alpha': 1.4135427462827407e-05,\n",
       " 'max_depth': 6,\n",
       " 'eta': 6.5886252538597155e-06,\n",
       " 'gamma': 0.00020302042169817732,\n",
       " 'subsample': 0.510358433878495,\n",
       " 'colsample_bytree': 0.36795046116791585,\n",
       " 'min_child_weight': 7,\n",
       " 'n_estimators': 208,\n",
       " 'learning_rate': 0.102853525134955}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-14 14:19:57,028] Trial 4 finished with value: 0.11428656366908585 and parameters: {'lambda': 0.010256838647360881, 'alpha': 1.960632320172698e-06, 'max_depth': 16, 'eta': 0.00029130595379468923, 'gamma': 2.062293051506125e-06, 'subsample': 0.4750957701306353, 'colsample_bytree': 0.2938224515497027, 'min_child_weight': 2, 'n_estimators': 763, 'learning_rate': 0.00012685726665235208}. Best is trial 3 with value: 0.08989768494458099.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Get the best hyperparameters from the study\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "display(best_params)\n",
    "# Create the final model using the best hyperparameters\n",
    "# final_model = ExtraTreesRegressor(**best_params, random_state=42)\n",
    "# final_model = ExtraTreesRegressor()\n",
    "final_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "# final_model = xgb.XGBRegressor()\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = final_model.predict(X_test)\n",
    "y_pred_train = final_model.predict(X_train)\n",
    "y_pred_valid = final_model.predict(X_valid)\n",
    "test_df = X_test.copy()\n",
    "test_df[\"y_nor\"] = y_test\n",
    "train_df = X_train.copy()\n",
    "train_df[\"y_nor\"] = y_train\n",
    "val_df = X_valid.copy()\n",
    "val_df[\"y_nor\"] = y_valid\n",
    "\n",
    "# Add the predictions to the test_df DataFrame\n",
    "test_df[\"predicted_y_nor\"] = y_pred_test\n",
    "\n",
    "train_df[\"predicted_y_nor\"] = y_pred_train\n",
    "val_df[\"predicted_y_nor\"] = y_pred_valid\n",
    "# Map store_id back to the test_df DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_correct 21\n",
      "accuracy 0.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Assuming you have the actual target values for the test set in y_test\n",
    "y_test = test_df[\"y_nor\"]\n",
    "\n",
    "# Extract predicted values from the DataFrame\n",
    "predictions = test_df[\"predicted_y_nor\"]\n",
    "test_df[\"mape\"] = abs(test_df[\"y_nor\"] - test_df[\"predicted_y_nor\"]) / test_df[\"y_nor\"]\n",
    "\n",
    "\n",
    "selected_columns = [\"y_nor\", \"predicted_y_nor\", \"mape\"]\n",
    "test_df[selected_columns].head()\n",
    "# count mape<0.15\n",
    "test_correct = test_df[test_df[\"mape\"] < 0.15].shape[0]\n",
    "test_df.shape[0]\n",
    "print(\"test_correct\", test_correct)\n",
    "print(f\"accuracy {test_correct / test_df.shape[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_correct 390\n",
      "accuracy 1.00\n"
     ]
    }
   ],
   "source": [
    "# val\n",
    "val_df[\"mape\"] = abs(val_df[\"y_nor\"] - val_df[\"predicted_y_nor\"]) / val_df[\"y_nor\"]\n",
    "val_correct = val_df[val_df[\"mape\"] < 0.15].shape[0]\n",
    "val_df.shape[0]\n",
    "print(\"val_correct\", val_correct)\n",
    "print(f\"accuracy {val_correct / val_df.shape[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_correct 2219\n",
      "accuracy 0.34\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train_df[\"mape\"] = (\n",
    "    abs(train_df[\"y_nor\"] - train_df[\"predicted_y_nor\"]) / train_df[\"y_nor\"]\n",
    ")\n",
    "train_correct = train_df[train_df[\"mape\"] < 0.15].shape[0]\n",
    "train_df.shape[0]\n",
    "print(\"train_correct\", train_correct)\n",
    "print(f\"accuracy {train_correct / train_df.shape[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
